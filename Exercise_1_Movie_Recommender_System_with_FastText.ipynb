{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nu_-xIqcvbuO"
   },
   "source": [
    "# Exercise 1 - Movie Recommender System with FastText Embeddings\n",
    "\n",
    "## Text Similarity\n",
    "\n",
    "Recommender systems are one of the popular and most adopted applications of machine learning. They are typically used to recommend entities to users and these entites can be anything like products, movies, services and so on.\n",
    "\n",
    "Popular examples of recommendations include,\n",
    "\n",
    "- Amazon suggesting products on its website\n",
    "- Amazon Prime, Netflix, Hotstar recommending movies\\shows\n",
    "- YouTube recommending videos to watch\n",
    "\n",
    "Typically recommender systems can be implemented in three ways:\n",
    "\n",
    "- Simple Rule-based Recommenders: Typically based on specific global metrics and thresholds like movie popularity, global ratings etc.\n",
    "- Content-based Recommenders: This is based on providing similar entities based on a specific entity of interest. Content metadata can be used here like movie descriptions, genre, cast, director and so on\n",
    "- Collaborative filtering Recommenders: Here we don't need metadata but we try to predict recommendations and ratings based on past ratings of different users and specific items.\n",
    "\n",
    "__We will be building a movie recommendation system here where based on data\\metadata pertaining to different movies, we try and recommend similar movies of interest!__\n",
    "\n",
    "With this exercise we will learn how to apply concepts learnt through tutorials of week1. Let's get started\n",
    "\n",
    "___Fill in the blanks \\ areas of code snippet with `<YOUR CODE HERE>` in the following code cells___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TS_vIju4vnQf"
   },
   "source": [
    "## Load Data\n",
    "\n",
    "If you are using google colab please use the upload file button option from the 'Files' icon on the left pane to upload the `tmdb_5000_movies.csv.gz` dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qr3XMWfJvMiG"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('tmdb_5000_movies.csv.gz', compression='gzip')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OPifQHRjvs7e"
   },
   "source": [
    "### **Question 1**: **View** top few rows of the dataframe (1 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hn0jo9IHvuGd"
   },
   "outputs": [],
   "source": [
    "df._______()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5h2081STv040"
   },
   "outputs": [],
   "source": [
    "column_list = ['title', 'tagline', 'overview', 'genres', 'popularity']\n",
    "df = df[column_list]\n",
    "df.tagline.fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u8y8-6tdv3qu"
   },
   "source": [
    "### **Question 2**: Merge text from tagline column with text from overview column (1 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VdBq30zUv2-r"
   },
   "outputs": [],
   "source": [
    "df['description'] = df['tagline'].map(str) + ' ' + ________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9YWpp8jLv8Z2"
   },
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yU--WPKcwEBs"
   },
   "source": [
    "## Text Preprocessing\n",
    "\n",
    "First step is to prepare the text columns for analysis. In this section we will prepare textual columns before we extract features from them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "leKwVGhfv8XR"
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oBH6mrhEv8Ud"
   },
   "outputs": [],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sQYjzqEnw9HH"
   },
   "source": [
    "### **Question 3**: Complete the text normalization utility function (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j42KNzQ8w-Bz"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "\n",
    "stop_words = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cpco9Ed_w9_3"
   },
   "outputs": [],
   "source": [
    "def normalize_document(doc):\n",
    "    # remove special characters\\whitespaces, ignore case\n",
    "    doc = <YOUR CODE HERE>\n",
    "\n",
    "    # lower case  \n",
    "    doc = <YOUR CODE HERE>\n",
    "\n",
    "    # remove whitespaces\n",
    "    doc = <YOUR CODE HERE>\n",
    "\n",
    "    # tokenize document\n",
    "    tokens = <YOUR CODE HERE>\n",
    "\n",
    "    # filter stopwords out of document\n",
    "    filtered_tokens = <YOUR CODE HERE>\n",
    "\n",
    "    # re-create/merge sentences from filtered content\n",
    "    doc = <YOUR CODE HERE>\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2vzO416Aw99H"
   },
   "outputs": [],
   "source": [
    "normalize_corpus = np.vectorize(normalize_document)\n",
    "\n",
    "norm_corpus = normalize_corpus(list(df['description']))\n",
    "len(norm_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QcfdT6fyfreF"
   },
   "outputs": [],
   "source": [
    "movies_list = df['title'].values\n",
    "movies_list, movies_list.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vJMe4XzPxk4S"
   },
   "source": [
    "## Movie Recommendation with Embeddings\n",
    "We used count based features in a similar assignment in the first course. Can we use word embeddings and then compute movie similarity? We definitely can! Here we will use the FastText model and train it on our corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r-uyv-bGxwrk"
   },
   "source": [
    "### **Question 4**: Use ``gensim`` to train a FastText model on the normalized corpus (1 point)\n",
    "\n",
    "You can keep:\n",
    "\n",
    "- the embedding size to be 300\n",
    "- context to be around 30\n",
    "- min word count to be 2 (feel free to try more if needed as a filter)\n",
    "- use a skipgram model\n",
    "- iterations can be 50 (reduce it if it takes too long)\n",
    "\n",
    "This might take a while to train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hOvj1gP2w9a4"
   },
   "outputs": [],
   "source": [
    "from gensim.models import FastText\n",
    "\n",
    "# iterate normalized corpus and split\n",
    "tokenized_docs = <YOUR CODE HERE>\n",
    "\n",
    "# Set values for various parameters\n",
    "feature_size = <YOUR CODE HERE>   # Set Word embedding dimensionality \n",
    "window_context = <YOUR CODE HERE>  # Set Context window size                                                                                  \n",
    "min_word_count = <YOUR CODE HERE>   # Set Minimum word count                    \n",
    "sg = <YOUR CODE HERE>               # set skip-gram model flag\n",
    "\n",
    "# train FastText model\n",
    "ft_model = <YOUR CODE HERE>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nfuTtrMmx_2z"
   },
   "source": [
    "##Generate document level embeddings\n",
    "\n",
    "Word embedding models give us an embedding for each word, how can we use it for downstream ML\\DL tasks? one way is to flatten it or use sequential models. A simpler approach is to average all word embeddings for words in a document and generate a fixed-length document level emebdding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Art_yII9yEh4"
   },
   "source": [
    "### **Question 5**: Complete the following utility to prepare document vectors by averaging word vectors (3 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C-za9YDAyBld"
   },
   "outputs": [],
   "source": [
    "def averaged_word2vec_vectorizer(corpus, model, num_features):\n",
    "    <YOUR CODE HERE>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K-ikl1OGyPI2"
   },
   "outputs": [],
   "source": [
    "doc_vecs_ft = averaged_word2vec_vectorizer(tokenized_docs, ft_model, 300)\n",
    "doc_vecs_ft.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3vsnxIasySJc"
   },
   "source": [
    "## Get Movie Recommendations\n",
    "\n",
    "Recommendations in its most simplest form is a method of identifying items which are most similar to given user's preferences. In this scenario we use a content based recommendation system which tries to find similar movies based on the movie content i.e. description.\n",
    "\n",
    "To identify similar items, we will use pairwise similarity measure called **cosine similarity**\n",
    "\n",
    "We will leverage cosine similarity to generate recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iiDBoSmCyYpe"
   },
   "source": [
    "### **Question 6**: Complete the following snippet to prepare a dataframe of pair-wise cosine similarity of different movies (1 point)\n",
    "\n",
    "Create pairwise cosine similarity based on the document embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pkFdzkbw2KpN"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VJ0OPwSKyT24"
   },
   "outputs": [],
   "source": [
    "doc_sim = <YOUR CODE HERE>\n",
    "doc_sim_df = pd.DataFrame(doc_sim)\n",
    "doc_sim_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MpVoDJNmOPBD"
   },
   "source": [
    "## Step by Step Methodology for Recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TGGJ_gJFuZ-o"
   },
   "source": [
    "### **Question 7**: Get a list of Movie titles (1 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QAMyZTC9ODZU"
   },
   "outputs": [],
   "source": [
    "# movie titles\n",
    "movies_list = <YOUR CODE HERE>\n",
    "movies_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TmMMPq3-ukJV"
   },
   "source": [
    "### **Question 8**: Given a movie title, get its index value (1 point)\n",
    "\n",
    "Here let's get the ID for the movie __Minions__\n",
    "\n",
    "__Hint:__ Numpy has dedicated functions to find the index from a numpy array or you can use list indexing functions also. The output should be a number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ze84U5EVOUhW"
   },
   "outputs": [],
   "source": [
    "## movie ID\n",
    "movie_idx = <YOUR CODE HERE>\n",
    "movie_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MoCHlZl9OYSk"
   },
   "source": [
    "## Get Similar Movies\n",
    "\n",
    "We already calculated pairwise similarity between all movies in our dataset. Next step is to extract moview similar to a given movie.\n",
    "\n",
    "Let us use the movie _Minions_ at index _546_ to find some similar movies using ``doc_sim_df`` dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "egLaZYx9vGP0"
   },
   "source": [
    "### **Question 9**: Extract row of dataframe given an index (1 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UmSNFxLxOUYA"
   },
   "outputs": [],
   "source": [
    "movie_similarities = <YOUR CODE HERE>\n",
    "movie_similarities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HLgaeRlcOeMv"
   },
   "source": [
    "### Top Similar Movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q-Oa0wvlvVVb"
   },
   "source": [
    "### **Question 10**: Get top 5 most similar movies in descending order of similarity (1 point)\n",
    "\n",
    "_hint: In descending order the index 0 represents the movie itself (as a movie description is 100% similar to itself, so it is safe to skip index 0_\n",
    "\n",
    "#### Get top 5 movie IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7MipUk82OjRh"
   },
   "outputs": [],
   "source": [
    "similar_movie_idxs = <YOUR CODE HERE>\n",
    "similar_movie_idxs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YvCvqUS1_I5n"
   },
   "source": [
    "#### Get top 5 movie names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kRofKIaaOlc1"
   },
   "outputs": [],
   "source": [
    "similar_movies = movies_list[similar_movie_idxs]\n",
    "similar_movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E3GRzdwOxVXa"
   },
   "source": [
    "## Movie Recommender\n",
    "\n",
    "Time to make use of all the smaller steps we have gone through so far to prepare a recommendation utility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lpB52SSIxbkk"
   },
   "source": [
    "### **Question 11**: Complete the utility function for getting movie recommendations (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dL9JZc_Tw96e"
   },
   "outputs": [],
   "source": [
    "def movie_recommender(movie_title, movies=movies_list, doc_sims=None):\n",
    "    # find movie id\n",
    "    movie_idx = <YOUR CODE HERE>\n",
    "\n",
    "    # get movie similarities. \n",
    "    #Hint: movie index helps find the exact row\n",
    "    movie_similarities = <YOUR CODE HERE>\n",
    "    \n",
    "    # get top 5 similar movie IDs\n",
    "    # Hint: use numpy utility to do a sort\n",
    "    similar_movie_idxs = <YOUR CODE HERE>\n",
    "    \n",
    "    # get top 5 movies\n",
    "    similar_movies = <YOUR CODE HERE>\n",
    "    \n",
    "    # return the top 5 movies\n",
    "    return similar_movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vkH9veWqyljn"
   },
   "source": [
    "### Find Similar Movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0b2mQR5yyxxY"
   },
   "outputs": [],
   "source": [
    "popular_movies = ['Minions', 'Interstellar', 'Deadpool', 'Jurassic World', 'Pirates of the Caribbean: The Curse of the Black Pearl',\n",
    "              'Dawn of the Planet of the Apes', 'The Hunger Games: Mockingjay - Part 1', 'Terminator Genisys', \n",
    "              'Captain America: Civil War', 'The Dark Knight', 'The Martian', 'Batman v Superman: Dawn of Justice', \n",
    "              'Pulp Fiction', 'The Godfather', 'The Shawshank Redemption', 'The Lord of the Rings: The Fellowship of the Ring',  \n",
    "              'Harry Potter and the Chamber of Secrets', 'Star Wars', 'The Hobbit: The Battle of the Five Armies',\n",
    "              'Iron Man']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xLtf6tM3ymN7"
   },
   "outputs": [],
   "source": [
    "for movie in popular_movies:\n",
    "    print('Movie:', movie)\n",
    "    print('Top 5 recommended Movies:', movie_recommender(movie_title=movie, movies=movies_list, doc_sims=doc_sim_df))\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Exercise 1 - Movie Recommender System with FastText.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
