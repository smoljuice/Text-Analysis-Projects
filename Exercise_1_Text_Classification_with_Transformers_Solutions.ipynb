{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sjp7WlCGajaa"
   },
   "source": [
    "# Deep Transfer Learning for Text Classification\n",
    "\n",
    "Handling tough real-world problems in Natural Language Processing (NLP) include tackling with class imbalance and the lack of availability of enough labeled data for training. Thanks to the recent advancements in deep transfer learning in NLP, we have been able to make rapid strides in not only tackling these problems but also leverage these models for diverse downstream NLP tasks.\n",
    "\n",
    "In this exercise you will be writing code to build a Hate Speech Classifier using:\n",
    "\n",
    "- BERT (fine-tuning)\n",
    "- DistilBERT (fine-tuning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CBtXjYJHajab"
   },
   "source": [
    "# GPU Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ro9zTCDIajab",
    "outputId": "1835228c-df61-4d76-ebc7-3b1e3585e329"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Apr  2 15:50:32 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.67       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   41C    P0    28W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8OQZquMCajaf"
   },
   "source": [
    "# Load Necessary Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q55jt2QJbSiC",
    "outputId": "929c21c9-9556-4a8f-ed97-72ed0f36b7dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ed/d5/f4157a376b8a79489a76ce6cfe147f4f3be1e029b7144fa7b8432e8acb26/transformers-4.4.2-py3-none-any.whl (2.0MB)\n",
      "\u001b[K     |████████████████████████████████| 2.0MB 4.5MB/s \n",
      "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
      "Collecting tokenizers<0.11,>=0.10.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/23/2ddc317b2121117bf34dd00f5b0de194158f2a44ee2bf5e47c7166878a97/tokenizers-0.10.1-cp37-cp37m-manylinux2010_x86_64.whl (3.2MB)\n",
      "\u001b[K     |████████████████████████████████| 3.2MB 18.0MB/s \n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
      "Collecting sacremoses\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
      "\u001b[K     |████████████████████████████████| 890kB 33.9MB/s \n",
      "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
      "Building wheels for collected packages: sacremoses\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp37-none-any.whl size=893262 sha256=dba0bd83d6dcafc5d1d7d4ac132472bd42d66c4841402ede2bc159fe7b612948\n",
      "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
      "Successfully built sacremoses\n",
      "Installing collected packages: tokenizers, sacremoses, transformers\n",
      "Successfully installed sacremoses-0.0.43 tokenizers-0.10.1 transformers-4.4.2\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "QORPi59-V8Jk",
    "outputId": "085e0135-e85e-4762-85bd-e3cbd91df304"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'4.4.2'"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers\n",
    "transformers.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "x8WniVpUajaf"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "w\n",
    "import transformers\n",
    "import tqdm\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tXp8U9ENajah",
    "outputId": "a82ec7ff-8463-43fc-ef90-85ef7b36655a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF Version:  2.4.1\n",
      "Eager mode:  True\n",
      "TF Hub version:  0.11.0\n",
      "WARNING:tensorflow:From <ipython-input-5-da00183a5adb>:4: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n",
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "print(\"TF Version: \", tf.__version__)\n",
    "print(\"Eager mode: \", tf.executing_eagerly())\n",
    "print(\"TF Hub version: \", hub.__version__)\n",
    "print(\"GPU is\", \"available\" if tf.test.is_gpu_available() else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5IYUA5Zlajak"
   },
   "source": [
    "## Load Dataset - Hate Speech\n",
    "\n",
    "Social media unfortunately is rampant with hate speech in the form of posts and comments. This is a practical example of perhaps building an automated hate speech detection system using NLP in the form of text classification.\n",
    "\n",
    "In this notebook, we will leverage an open sourced collection of hate speech posts and comments.\n",
    "\n",
    "The dataset is available here: [kaggle](https://www.kaggle.com/usharengaraju/dynamically-generated-hate-speech-dataset) which in turn has been curated from a wider [data source for hate speech](https://hatespeechdata.com/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V20BvLjjajal",
    "outputId": "23acd2f5-e848-4380-db99-527125bf6e43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40623 entries, 0 to 40622\n",
      "Data columns (total 11 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Unnamed: 0      40623 non-null  int64  \n",
      " 1   id              40623 non-null  object \n",
      " 2   text            40623 non-null  object \n",
      " 3   label           40623 non-null  object \n",
      " 4   type            40623 non-null  object \n",
      " 5   model_wrong     26097 non-null  object \n",
      " 6   db.model_preds  26097 non-null  float64\n",
      " 7   status          40623 non-null  object \n",
      " 8   round           40623 non-null  object \n",
      " 9   split           40623 non-null  object \n",
      " 10  annotator       40623 non-null  object \n",
      "dtypes: float64(1), int64(1), object(9)\n",
      "memory usage: 3.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('HateDataset.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-DQuqZoRS9rz"
   },
   "source": [
    "# Subset Dataset\n",
    "\n",
    "BERT is a HUGE model which takes a long time to fine-tune!  \n",
    "\n",
    "So let's try to subset our data so you can work with a small dataset and train faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "ZDDJCvjrajan",
    "outputId": "503fd693-bb3a-443b-894c-f2bac8e250eb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35140</th>\n",
       "      <td>last week they were both in the kitchen and th...</td>\n",
       "      <td>hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18851</th>\n",
       "      <td>this is getting out of hand now, I have had 5 ...</td>\n",
       "      <td>hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18407</th>\n",
       "      <td>I love how hateful immigrants are</td>\n",
       "      <td>hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31427</th>\n",
       "      <td>I remember going to the beach, we stopped at a...</td>\n",
       "      <td>hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7212</th>\n",
       "      <td>don't call this worthless piece of shit a car!</td>\n",
       "      <td>nothate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text    label\n",
       "35140  last week they were both in the kitchen and th...     hate\n",
       "18851  this is getting out of hand now, I have had 5 ...     hate\n",
       "18407                  I love how hateful immigrants are     hate\n",
       "31427  I remember going to the beach, we stopped at a...     hate\n",
       "7212      don't call this worthless piece of shit a car!  nothate"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[['text', 'label']]\n",
    "df = df.sample(10000, random_state=42)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TdMiB1EFajap"
   },
   "source": [
    "# Preparing Train, Validation and Test Datasets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4ergvVKSUxhj"
   },
   "source": [
    "### Prepare Train-Test Split. Keep test set to be 20% of the total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "BiHTDHD_ajap"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_reviews, test_reviews, train_labels, test_labels = train_test_split(df.text.values,\n",
    "                                                                          df.label.values,\n",
    "                                                                          test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tJ6MU6B0ITH4",
    "outputId": "a3325064-2384-44bd-e4c0-02d5506f0628"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 2000)"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_reviews), len(test_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yXDBz_qqajas"
   },
   "source": [
    "# No Text Pre-processing\n",
    "\n",
    "__Note:__ For some models we don't use any pre-processing like BERT! It should be able to handle a wide variety of text in its natural format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K9ZD5JPwU1sO"
   },
   "source": [
    "## Label Encode Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b4G7RK_tU3t5"
   },
   "source": [
    "# **Question 1**: Label Encode Class Labels\n",
    "\n",
    "`hate` and `nothate` needs to be encoded to numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "JlEtGVoFIpfW"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "y_train = le.fit_transform(train_labels)\n",
    "y_test = le.transform(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O-YydwrQajcM"
   },
   "source": [
    "# Model 1: BERT (Bi-directional Encoder Representations from Transformers)\n",
    "\n",
    "We will be using the BERT base model which has already been pre-trained by Google on MLM + Next Sentence Prediction Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0OIAAHBPajcM"
   },
   "source": [
    "## BERT Tokenization\n",
    "\n",
    "The BERT model we're using expects lowercase data. Here we leverage Huggingface `transformers`' `BertTokenizer`, which breaks words into word pieces.\n",
    "\n",
    "Word Piece Tokenizer is based on [Byte Pair Encodings (BPE)](https://www.aclweb.org/anthology/P16-1162).\n",
    "\n",
    "WordPiece and BPE are two similar and commonly used techniques to segment words into subword-level in NLP tasks. In both cases, the vocabulary is initialized with all the individual characters in the language, and then the most frequent/likely combinations of the symbols in the vocabulary are iteratively added to the vocabulary.\n",
    "\n",
    "magine that the model sees the word walking. Unless this word occurs at least a few times in the training corpus, the model can't learn to deal with this word very well. However, it may have the words walked, walker, walks, each occurring only a few times. Without subword segmentation, all these words are treated as completely different words by the model.\n",
    "\n",
    "However, if these get segmented as walk@@ ing, walk@@ ed, etc., notice that all of them will now have walk@@ in common, which will occur much frequently while training, and the model might be able to learn more about it.\n",
    "\n",
    "Huggingface's transformers library has easy to use utilities for each type of model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3cuHh91_U-RZ"
   },
   "source": [
    "# **Question 2**: Load BERT Tokenizer\n",
    "\n",
    "_Hint: Use ``transformers.BertTokenizer.from_pretrained`` with the right pretrained model (bert base uncased) similar to the tutorial_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 164,
     "referenced_widgets": [
      "8bf6ee1bf58542b5a540a596187d1cd0",
      "485838d0fa254106a47a61bc15d8fe15",
      "82f87619deb348269edea2ec2bb4daa4",
      "b02826893ac64bc7b102c2ee93243a6c",
      "03d6fb259ee74891b89607d1c834f723",
      "28d40d5c348b4110bd873032e9d40b1f",
      "c5441a797c4f408889838bc39ec7d989",
      "2a350889751b4188b87fd633726855e8",
      "b20b405e645a437b842b7d6311a4b14d",
      "445e41d578324e6e9df3db2d126888ee",
      "709b044181be46958970fa9d08722f2a",
      "ce0e64f99a4f40e6aa27f81799f67dae",
      "47e14d442dd342c8b72e338c3ea1c25c",
      "d0d70138091246ca99e54353fa20194b",
      "733f1f8147004e769ff009a9a5b4cfca",
      "46a0e558e4774da3ae59e239e675992c",
      "7d16d30ba58f45cd9c30cb5bc495e4a8",
      "4fd51fef05bd4b9cb1d8d2fc84dd9368",
      "700116ef30a945548d93dfbd7ad8de5a",
      "973541e37168414da8b21638d461c38b",
      "3f9e8d84d44e480aab8892adf8742d09",
      "6dc95aeabad04f1488706ac5abdc6a53",
      "3b7258aad07d483e95fac01432185857",
      "6a72dd6dc7a941e1a6568de138516e5c"
     ]
    },
    "id": "E1BtlCzfajcM",
    "outputId": "bd2f43fe-5cdb-4114-8ecb-f13a5d1fd90c"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bf6ee1bf58542b5a540a596187d1cd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b20b405e645a437b842b7d6311a4b14d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=28.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d16d30ba58f45cd9c30cb5bc495e4a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=466062.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = transformers.BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0EKS_rEpajcN"
   },
   "source": [
    "## BERT Data Preparation\n",
    "\n",
    "We need to preprocess our data so that it matches the data format BERT was trained on. For this, we'll need to do a couple of things.\n",
    "\n",
    "- Lowercase our text (if we're using a BERT lowercase model)\n",
    "- Tokenize it (i.e. \"sally says hi\" -> [\"sally\", \"says\", \"hi\"])\n",
    "- Break words into WordPieces (i.e. \"calling\" -> [\"call\", \"##ing\"])\n",
    "- Map our words to indexes using a vocab file that BERT provides\n",
    "- Add special \"CLS\" and \"SEP\" tokens (see the readme)\n",
    "- Append \"mask\" and \"segment\" tokens to each input (see the BERT paper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "szOzzJUQa8hJ"
   },
   "source": [
    "# **Question 3**: Create function to tokenize and encode text into BERT token IDs\n",
    "\n",
    "Use a similar strategy as you learnt in the tutorial and fill in the following function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "MAEd7xjIajcO"
   },
   "outputs": [],
   "source": [
    "def create_bert_input_features(tokenizer, docs, max_seq_length):\n",
    "    \n",
    "    all_ids, all_masks, all_segments= [], [], []\n",
    "    for doc in tqdm.tqdm(docs, desc=\"Converting docs to features\"):\n",
    "        \n",
    "        tokens = tokenizer.tokenize(doc)\n",
    "        \n",
    "        if len(tokens) > max_seq_length-2:\n",
    "            tokens = tokens[0 : (max_seq_length-2)]\n",
    "        tokens = ['[CLS]'] + tokens + ['[SEP]']\n",
    "        ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "        masks = [1] * len(ids) \n",
    "        \n",
    "        # Zero-pad up to the sequence length.\n",
    "        while len(ids) < max_seq_length:\n",
    "            ids.append(0)\n",
    "            masks.append(0)\n",
    "            \n",
    "        segments = [0] * max_seq_length \n",
    "        all_ids.append(ids)\n",
    "        all_masks.append(masks)\n",
    "        all_segments.append(segments)\n",
    "        \n",
    "    encoded = np.array([all_ids, all_masks, all_segments])\n",
    "    \n",
    "    return encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tkqG8EQLajcQ"
   },
   "source": [
    "# **Question 4**: Build Model Architecture\n",
    "\n",
    "Use a similar model architecture as the tutorial with a max sequence length of 500 tokens to be used.\n",
    "\n",
    "You can always experiment with aspects like learning rate, number of layers etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WTEpLgzjajcQ",
    "outputId": "03cf539f-85c0-4987-d61d-5fd627a9770e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "bert_input_ids (InputLayer)     [(None, 500)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bert_input_masks (InputLayer)   [(None, 500)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bert_segment_ids (InputLayer)   [(None, 500)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_bert_model_1 (TFBertModel)   TFBaseModelOutputWit 109482240   bert_input_ids[0][0]             \n",
      "                                                                 bert_input_masks[0][0]           \n",
      "                                                                 bert_segment_ids[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 256)          196864      tf_bert_model_1[0][1]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_76 (Dropout)            (None, 256)          0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 256)          65792       dropout_76[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_77 (Dropout)            (None, 256)          0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 1)            257         dropout_77[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 109,745,153\n",
      "Trainable params: 109,745,153\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "MAX_SEQ_LENGTH = 500\n",
    "\n",
    "inp_id = tf.keras.layers.Input(shape=(MAX_SEQ_LENGTH,), dtype='int32', name=\"bert_input_ids\")\n",
    "inp_mask = tf.keras.layers.Input(shape=(MAX_SEQ_LENGTH,), dtype='int32', name=\"bert_input_masks\")\n",
    "inp_segment = tf.keras.layers.Input(shape=(MAX_SEQ_LENGTH,), dtype='int32', name=\"bert_segment_ids\")\n",
    "inputs = [inp_id, inp_mask, inp_segment]\n",
    "\n",
    "hidden_state = transformers.TFBertModel.from_pretrained('bert-base-uncased')(inputs)\n",
    "pooled_output = hidden_state[1]\n",
    "\n",
    "dense1 = tf.keras.layers.Dense(256, activation='relu')(pooled_output)\n",
    "drop1 = tf.keras.layers.Dropout(0.25)(dense1)\n",
    "dense2 = tf.keras.layers.Dense(256, activation='relu')(drop1)\n",
    "drop2 = tf.keras.layers.Dropout(0.25)(dense2)\n",
    "\n",
    "output = tf.keras.layers.Dense(1, activation='sigmoid')(drop2)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=output)\n",
    "\n",
    "model.compile(optimizer=tf.optimizers.Adam(learning_rate=2e-5, \n",
    "                                           epsilon=1e-08), \n",
    "              loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zRTMV4jMajcR"
   },
   "source": [
    "## Convert text to BERT input features\n",
    "\n",
    "We leverage our utility function we created earlier to convert our text documents into BERT input features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CeUQ0WybVD2m"
   },
   "source": [
    "# **Question 5**: Prepare Feature ID, masks and segments for train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NC_9wq2fajcS",
    "outputId": "2f582cc3-ecfa-427a-d537-96cddac365ff"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting docs to features: 100%|██████████| 8000/8000 [00:04<00:00, 1730.17it/s]\n",
      "Converting docs to features: 100%|██████████| 2000/2000 [00:01<00:00, 1803.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Features: (8000, 500) (8000, 500) (8000, 500)\n",
      "Test Features: (2000, 500) (2000, 500) (2000, 500)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_features_ids, train_features_masks, train_features_segments = create_bert_input_features(tokenizer, \n",
    "                                                                                               train_reviews, \n",
    "                                                                                               max_seq_length=MAX_SEQ_LENGTH)\n",
    "\n",
    "test_features_ids, test_features_masks, test_features_segments = create_bert_input_features(tokenizer, \n",
    "                                                                                         test_reviews, \n",
    "                                                                                         max_seq_length=MAX_SEQ_LENGTH)\n",
    "\n",
    "print('Train Features:', train_features_ids.shape, train_features_masks.shape, train_features_segments.shape)\n",
    "print('Test Features:', test_features_ids.shape, test_features_masks.shape, test_features_segments.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_AxRNcQ5ajcT"
   },
   "source": [
    "## Train and Validate Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "it9y1wnKVKji"
   },
   "source": [
    "# **Question 6**: Train the Model\n",
    "\n",
    "You can train it for around 3 epochs as it takes a fair bit of time to train even on a good GPU\n",
    "\n",
    "For validation data you can use the test data tokens from the previous cell to keep things simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ys_e6K0-ajcU",
    "outputId": "e21585ff-ca4b-43c5-d0d0-7903efd00b21"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "667/667 [==============================] - ETA: 0s - loss: 0.6665 - accuracy: 0.5971WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "667/667 [==============================] - 597s 874ms/step - loss: 0.6665 - accuracy: 0.5972 - val_loss: 0.4952 - val_accuracy: 0.7610\n",
      "Epoch 2/3\n",
      "667/667 [==============================] - 580s 870ms/step - loss: 0.4358 - accuracy: 0.8006 - val_loss: 0.3992 - val_accuracy: 0.8140\n",
      "Epoch 3/3\n",
      "667/667 [==============================] - 580s 870ms/step - loss: 0.2553 - accuracy: 0.9005 - val_loss: 0.3980 - val_accuracy: 0.8345\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f56c50ea390>"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([train_features_ids, \n",
    "           train_features_masks, \n",
    "           train_features_segments], y_train, \n",
    "          validation_data=([test_features_ids, \n",
    "                            test_features_masks, \n",
    "                            test_features_segments], y_test),\n",
    "          epochs=3, \n",
    "          batch_size=12, \n",
    "          shuffle=True,\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nb_lPfpSajcY"
   },
   "source": [
    "# **Question 7**: Model Performance Evaluation on the Test Dataset\n",
    "\n",
    "Show the model's performance on the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uSuV86S0ajcY",
    "outputId": "6c49cd23-e5c7-42ce-ade2-f3831efea37b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    }
   ],
   "source": [
    "predictions = [1 if pr > 0.5 else 0 \n",
    "                   for pr in model.predict([test_features_ids, \n",
    "                                            test_features_masks, \n",
    "                                            test_features_segments], verbose=0).ravel()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "id": "Ns19Ky_PZ8YL",
    "outputId": "fcff6af7-d55b-412a-99a6-8276b7dc933d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 83.45%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.87      0.85      1063\n",
      "           1       0.85      0.79      0.82       937\n",
      "\n",
      "    accuracy                           0.83      2000\n",
      "   macro avg       0.84      0.83      0.83      2000\n",
      "weighted avg       0.84      0.83      0.83      2000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>929</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>197</td>\n",
       "      <td>740</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1\n",
       "0  929  134\n",
       "1  197  740"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Accuracy: %.2f%%\" % (accuracy_score(y_test, predictions)*100))\n",
    "print(classification_report(y_test, predictions))\n",
    "pd.DataFrame(confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AD9ANmhoajcZ"
   },
   "source": [
    "# Model 2: DistilBERT (Distilled BERT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CgsGB-UWajcZ"
   },
   "source": [
    "## BERT Tokenization\n",
    "\n",
    "The DistilBERT model we're using expects lowercase data. Here we leverage Huggingface `transformers`' `DistilBertTokenizer`, which breaks words into word pieces.\n",
    "\n",
    "Word Piece Tokenizer is based on [Byte Pair Encodings (BPE)](https://www.aclweb.org/anthology/P16-1162).\n",
    "\n",
    "WordPiece and BPE are two similar and commonly used techniques to segment words into subword-level in NLP tasks. In both cases, the vocabulary is initialized with all the individual characters in the language, and then the most frequent/likely combinations of the symbols in the vocabulary are iteratively added to the vocabulary.\n",
    "\n",
    "magine that the model sees the word walking. Unless this word occurs at least a few times in the training corpus, the model can't learn to deal with this word very well. However, it may have the words walked, walker, walks, each occurring only a few times. Without subword segmentation, all these words are treated as completely different words by the model.\n",
    "\n",
    "However, if these get segmented as walk@@ ing, walk@@ ed, etc., notice that all of them will now have walk@@ in common, which will occur much frequently while training, and the model might be able to learn more about it.\n",
    "\n",
    "Huggingface's transformers library has easy to use utilities for each type of model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eANXRl8BVPvG"
   },
   "source": [
    "# **Question 8**: Load DistilBERT Tokenizer\n",
    "\n",
    "_Hint: Use ``transformers.DistilBertTokenizer.from_pretrained`` with the right pretrained model (distilbert base uncased) similar to the tutorial_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 164,
     "referenced_widgets": [
      "a982e07377324884b5e441d9ad402f54",
      "6bebd4a2556f40b2a683079d0dfbbc9d",
      "0c776001201b4a7c9f5569b0fc1a5e7d",
      "8e2822ec81654fe98a7306a9d5758444",
      "f2d7e9ea975546df8ea54e18a4f34d79",
      "233c5fc507bf4680bb56ce3bcb7aa22c",
      "20ae19488a014ad6aa54c91956c421c1",
      "67dd2d2732ba440fb290cde0a09e5ce1",
      "08dc65b691434355b719e920ae29e755",
      "9f2acc022c02417cae7370aafbbfc8ab",
      "60954357024740e8b83ad5f12b67e909",
      "86d2323c7b444254bbb43b90ec406be6",
      "dd03a6a14f074d33871e33c996996437",
      "b43908d4b3914ccd84bcb90b013d9671",
      "ca9474392a2843ef997274cd84b20d54",
      "21a8ae3880364a97bfe0565efe6f494a",
      "c4296084fa294eeda720a464607b8d3f",
      "3ccc625bb43c460ebec51633aee144cb",
      "1f00398c5ddc473f87d2050c2fce1d50",
      "e36e4457266c4df2bd6cd6e6f15297e3",
      "024895ba4dc442498e18895b8d009838",
      "d9605a26b50f43469912a39f02bcd8d1",
      "84a6d20bb0ac4fe5886b723f1305979e",
      "2ebb87a4a2694639a0abdb68c298f803"
     ]
    },
    "id": "Q9H4AeL_ajcZ",
    "outputId": "d3ccd7f4-80f9-4e75-d5e8-513bff754d43"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a982e07377324884b5e441d9ad402f54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08dc65b691434355b719e920ae29e755",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=28.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4296084fa294eeda720a464607b8d3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=466062.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = transformers.DistilBertTokenizer.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ETJDWVw0ajca"
   },
   "source": [
    "## DistilBERT Data Preparation\n",
    "\n",
    "We need to preprocess our data so that it matches the data format DistilBERT was trained on. For this, we'll need to do a couple of things.\n",
    "\n",
    "- Lowercase our text (if we're using a BERT lowercase model)\n",
    "- Tokenize it (i.e. \"sally says hi\" -> [\"sally\", \"says\", \"hi\"])\n",
    "- Break words into WordPieces (i.e. \"calling\" -> [\"call\", \"##ing\"])\n",
    "- Map our words to indexes using a vocab file that BERT provides\n",
    "- Add special \"CLS\" and \"SEP\" tokens (see the readme)\n",
    "- Append \"mask\" tokens to each input (see https://medium.com/huggingface/distilbert-8cf3380435b5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i0fEfbhEk24b"
   },
   "source": [
    "# **Question 9**: Create function to tokenize and encode text into DistilBERT token IDs\n",
    "\n",
    "Use a similar strategy as you learnt in the tutorial and fill in the following function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "azjnxnFRajcb"
   },
   "outputs": [],
   "source": [
    "def create_bert_input_features(tokenizer, docs, max_seq_length):\n",
    "    \n",
    "    all_ids, all_masks = [], []\n",
    "    for doc in tqdm.tqdm(docs, desc=\"Converting docs to features\"):\n",
    "        \n",
    "        tokens = tokenizer.tokenize(doc)\n",
    "        \n",
    "        if len(tokens) > max_seq_length-2:\n",
    "            tokens = tokens[0 : (max_seq_length-2)]\n",
    "        tokens = ['[CLS]'] + tokens + ['[SEP]']\n",
    "        ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "        masks = [1] * len(ids)\n",
    "        \n",
    "        # Zero-pad up to the sequence length.\n",
    "        while len(ids) < max_seq_length:\n",
    "            ids.append(0)\n",
    "            masks.append(0)\n",
    "            \n",
    "        all_ids.append(ids)\n",
    "        all_masks.append(masks)\n",
    "        \n",
    "    encoded = np.array([all_ids, all_masks])\n",
    "    \n",
    "    return encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8SoR1dwHajcc"
   },
   "source": [
    "# **Question 10**: Build Model Architecture\n",
    "\n",
    "Use a similar model architecture as the tutorial with a max sequence length of 500 tokens to be used.\n",
    "\n",
    "You can always experiment with aspects like learning rate, number of layers etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EvdzoH7vajcc",
    "outputId": "af094013-d195-4c98-e327-75ac49b94a3b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertModel: ['vocab_transform', 'activation_13', 'vocab_projector', 'vocab_layer_norm']\n",
      "- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "bert_input_ids (InputLayer)     [(None, 500)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bert_input_masks (InputLayer)   [(None, 500)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_distil_bert_model_1 (TFDisti TFBaseModelOutput(la 66362880    bert_input_ids[0][0]             \n",
      "                                                                 bert_input_masks[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_1 (Sli (None, 768)          0           tf_distil_bert_model_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 256)          196864      tf.__operators__.getitem_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dropout_118 (Dropout)           (None, 256)          0           dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 256)          65792       dropout_118[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_119 (Dropout)           (None, 256)          0           dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 1)            257         dropout_119[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 66,625,793\n",
      "Trainable params: 66,625,793\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "MAX_SEQ_LENGTH = 500\n",
    "\n",
    "inp_id = tf.keras.layers.Input(shape=(MAX_SEQ_LENGTH,), dtype='int32', name=\"bert_input_ids\")\n",
    "inp_mask = tf.keras.layers.Input(shape=(MAX_SEQ_LENGTH,), dtype='int32', name=\"bert_input_masks\")\n",
    "inputs = [inp_id, inp_mask]\n",
    "\n",
    "hidden_state = transformers.TFDistilBertModel.from_pretrained('distilbert-base-uncased')(inputs)[0]\n",
    "pooled_output = hidden_state[:, 0]    \n",
    "\n",
    "dense1 = tf.keras.layers.Dense(256, activation='relu')(pooled_output)\n",
    "drop1 = tf.keras.layers.Dropout(0.25)(dense1)\n",
    "dense2 = tf.keras.layers.Dense(256, activation='relu')(drop1)\n",
    "drop2 = tf.keras.layers.Dropout(0.25)(dense2)\n",
    "\n",
    "output = tf.keras.layers.Dense(1, activation='sigmoid')(drop2)\n",
    "\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=output)\n",
    "model.compile(optimizer=tf.optimizers.Adam(learning_rate=2e-5, \n",
    "                                           epsilon=1e-08), \n",
    "              loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j-0k79jRajce"
   },
   "source": [
    "# **Question 11**: Prepare Feature ID, masks and segments for train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dEZtopKYajcf",
    "outputId": "8c6c71de-e3b7-475f-fa2e-eaa4d413cdde"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting docs to features: 100%|██████████| 8000/8000 [00:04<00:00, 1747.78it/s]\n",
      "Converting docs to features: 100%|██████████| 2000/2000 [00:01<00:00, 1820.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Features: (8000, 500) (8000, 500)\n",
      "Val Features: (2000, 500) (2000, 500)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_features_ids, train_features_masks = create_bert_input_features(tokenizer, train_reviews, \n",
    "                                                                      max_seq_length=MAX_SEQ_LENGTH)\n",
    "test_features_ids, test_features_masks = create_bert_input_features(tokenizer, test_reviews, \n",
    "                                                                  max_seq_length=MAX_SEQ_LENGTH)\n",
    "\n",
    "\n",
    "print('Train Features:', train_features_ids.shape, train_features_masks.shape)\n",
    "print('Val Features:', test_features_ids.shape, test_features_masks.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q316Jw8jajcg"
   },
   "source": [
    "## Train and Validate Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xu06rG3MVfQI"
   },
   "source": [
    "# **Question 12**: Train the Model\n",
    "\n",
    "You can train it for around 3 epochs as it takes a fair bit of time to train even on a good GPU\n",
    "\n",
    "For validation data you can use the test data tokens from the previous cell to keep things simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k4UqJQTOajcg",
    "outputId": "16acbfb0-8c38-4b23-e14a-43bfd5f97ac9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "534/534 [==============================] - ETA: 0s - loss: 0.6249 - accuracy: 0.6312WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "534/534 [==============================] - 290s 529ms/step - loss: 0.6248 - accuracy: 0.6313 - val_loss: 0.4442 - val_accuracy: 0.7905\n",
      "Epoch 2/3\n",
      "534/534 [==============================] - 281s 527ms/step - loss: 0.3735 - accuracy: 0.8347 - val_loss: 0.4150 - val_accuracy: 0.8150\n",
      "Epoch 3/3\n",
      "534/534 [==============================] - 281s 527ms/step - loss: 0.2192 - accuracy: 0.9120 - val_loss: 0.4352 - val_accuracy: 0.8260\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f5395152a50>"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([train_features_ids, \n",
    "           train_features_masks], y_train, \n",
    "          validation_data=([test_features_ids, \n",
    "                            test_features_masks], y_test),\n",
    "          epochs=3, \n",
    "          batch_size=15, \n",
    "          shuffle=True,\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OcxGMWWcajcl"
   },
   "source": [
    "# **Question 13**: Model Performance Evaluation on the Test Dataset\n",
    "\n",
    "Show the model's performance on the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 335
    },
    "id": "xEVSsaBBajcl",
    "outputId": "d00e5f35-7037-4057-9b17-8aa7efda159d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "Accuracy: 82.60%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.84      0.84      1063\n",
      "           1       0.82      0.80      0.81       937\n",
      "\n",
      "    accuracy                           0.83      2000\n",
      "   macro avg       0.83      0.82      0.83      2000\n",
      "weighted avg       0.83      0.83      0.83      2000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>898</td>\n",
       "      <td>165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>183</td>\n",
       "      <td>754</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1\n",
       "0  898  165\n",
       "1  183  754"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = [1 if pr > 0.5 else 0 \n",
    "                   for pr in model.predict([test_features_ids, \n",
    "                                            test_features_masks], batch_size=200, verbose=0).ravel()]\n",
    "\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy_score(y_test, predictions)*100))\n",
    "print(classification_report(y_test, predictions))\n",
    "pd.DataFrame(confusion_matrix(y_test, predictions))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Exercise 1 - Text Classification with Transformers - Solutions.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "024895ba4dc442498e18895b8d009838": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "03d6fb259ee74891b89607d1c834f723": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "08dc65b691434355b719e920ae29e755": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_60954357024740e8b83ad5f12b67e909",
       "IPY_MODEL_86d2323c7b444254bbb43b90ec406be6"
      ],
      "layout": "IPY_MODEL_9f2acc022c02417cae7370aafbbfc8ab"
     }
    },
    "0c776001201b4a7c9f5569b0fc1a5e7d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_233c5fc507bf4680bb56ce3bcb7aa22c",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f2d7e9ea975546df8ea54e18a4f34d79",
      "value": 231508
     }
    },
    "1f00398c5ddc473f87d2050c2fce1d50": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d9605a26b50f43469912a39f02bcd8d1",
      "max": 466062,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_024895ba4dc442498e18895b8d009838",
      "value": 466062
     }
    },
    "20ae19488a014ad6aa54c91956c421c1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "21a8ae3880364a97bfe0565efe6f494a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "233c5fc507bf4680bb56ce3bcb7aa22c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "28d40d5c348b4110bd873032e9d40b1f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2a350889751b4188b87fd633726855e8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2ebb87a4a2694639a0abdb68c298f803": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3b7258aad07d483e95fac01432185857": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3ccc625bb43c460ebec51633aee144cb": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3f9e8d84d44e480aab8892adf8742d09": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "445e41d578324e6e9df3db2d126888ee": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "46a0e558e4774da3ae59e239e675992c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "47e14d442dd342c8b72e338c3ea1c25c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "485838d0fa254106a47a61bc15d8fe15": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4fd51fef05bd4b9cb1d8d2fc84dd9368": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "60954357024740e8b83ad5f12b67e909": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b43908d4b3914ccd84bcb90b013d9671",
      "max": 28,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_dd03a6a14f074d33871e33c996996437",
      "value": 28
     }
    },
    "67dd2d2732ba440fb290cde0a09e5ce1": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6a72dd6dc7a941e1a6568de138516e5c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6bebd4a2556f40b2a683079d0dfbbc9d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6dc95aeabad04f1488706ac5abdc6a53": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "700116ef30a945548d93dfbd7ad8de5a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6dc95aeabad04f1488706ac5abdc6a53",
      "max": 466062,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3f9e8d84d44e480aab8892adf8742d09",
      "value": 466062
     }
    },
    "709b044181be46958970fa9d08722f2a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d0d70138091246ca99e54353fa20194b",
      "max": 28,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_47e14d442dd342c8b72e338c3ea1c25c",
      "value": 28
     }
    },
    "733f1f8147004e769ff009a9a5b4cfca": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7d16d30ba58f45cd9c30cb5bc495e4a8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_700116ef30a945548d93dfbd7ad8de5a",
       "IPY_MODEL_973541e37168414da8b21638d461c38b"
      ],
      "layout": "IPY_MODEL_4fd51fef05bd4b9cb1d8d2fc84dd9368"
     }
    },
    "82f87619deb348269edea2ec2bb4daa4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_28d40d5c348b4110bd873032e9d40b1f",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_03d6fb259ee74891b89607d1c834f723",
      "value": 231508
     }
    },
    "84a6d20bb0ac4fe5886b723f1305979e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "86d2323c7b444254bbb43b90ec406be6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_21a8ae3880364a97bfe0565efe6f494a",
      "placeholder": "​",
      "style": "IPY_MODEL_ca9474392a2843ef997274cd84b20d54",
      "value": " 28.0/28.0 [00:00&lt;00:00, 197B/s]"
     }
    },
    "8bf6ee1bf58542b5a540a596187d1cd0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_82f87619deb348269edea2ec2bb4daa4",
       "IPY_MODEL_b02826893ac64bc7b102c2ee93243a6c"
      ],
      "layout": "IPY_MODEL_485838d0fa254106a47a61bc15d8fe15"
     }
    },
    "8e2822ec81654fe98a7306a9d5758444": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_67dd2d2732ba440fb290cde0a09e5ce1",
      "placeholder": "​",
      "style": "IPY_MODEL_20ae19488a014ad6aa54c91956c421c1",
      "value": " 232k/232k [00:00&lt;00:00, 574kB/s]"
     }
    },
    "973541e37168414da8b21638d461c38b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6a72dd6dc7a941e1a6568de138516e5c",
      "placeholder": "​",
      "style": "IPY_MODEL_3b7258aad07d483e95fac01432185857",
      "value": " 466k/466k [00:00&lt;00:00, 4.98MB/s]"
     }
    },
    "9f2acc022c02417cae7370aafbbfc8ab": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a982e07377324884b5e441d9ad402f54": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0c776001201b4a7c9f5569b0fc1a5e7d",
       "IPY_MODEL_8e2822ec81654fe98a7306a9d5758444"
      ],
      "layout": "IPY_MODEL_6bebd4a2556f40b2a683079d0dfbbc9d"
     }
    },
    "b02826893ac64bc7b102c2ee93243a6c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2a350889751b4188b87fd633726855e8",
      "placeholder": "​",
      "style": "IPY_MODEL_c5441a797c4f408889838bc39ec7d989",
      "value": " 232k/232k [00:00&lt;00:00, 1.10MB/s]"
     }
    },
    "b20b405e645a437b842b7d6311a4b14d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_709b044181be46958970fa9d08722f2a",
       "IPY_MODEL_ce0e64f99a4f40e6aa27f81799f67dae"
      ],
      "layout": "IPY_MODEL_445e41d578324e6e9df3db2d126888ee"
     }
    },
    "b43908d4b3914ccd84bcb90b013d9671": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c4296084fa294eeda720a464607b8d3f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1f00398c5ddc473f87d2050c2fce1d50",
       "IPY_MODEL_e36e4457266c4df2bd6cd6e6f15297e3"
      ],
      "layout": "IPY_MODEL_3ccc625bb43c460ebec51633aee144cb"
     }
    },
    "c5441a797c4f408889838bc39ec7d989": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ca9474392a2843ef997274cd84b20d54": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ce0e64f99a4f40e6aa27f81799f67dae": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_46a0e558e4774da3ae59e239e675992c",
      "placeholder": "​",
      "style": "IPY_MODEL_733f1f8147004e769ff009a9a5b4cfca",
      "value": " 28.0/28.0 [00:00&lt;00:00, 125B/s]"
     }
    },
    "d0d70138091246ca99e54353fa20194b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d9605a26b50f43469912a39f02bcd8d1": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dd03a6a14f074d33871e33c996996437": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "e36e4457266c4df2bd6cd6e6f15297e3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2ebb87a4a2694639a0abdb68c298f803",
      "placeholder": "​",
      "style": "IPY_MODEL_84a6d20bb0ac4fe5886b723f1305979e",
      "value": " 466k/466k [00:00&lt;00:00, 4.46MB/s]"
     }
    },
    "f2d7e9ea975546df8ea54e18a4f34d79": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
