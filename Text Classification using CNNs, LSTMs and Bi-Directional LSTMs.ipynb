{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0KgS-rz5d7Ok"
   },
   "source": [
    "# Exercise 1: Text Classification using CNNs, LSTMs and Bi-Directional LSTMs\n",
    "\n",
    "Understanding the text content and predicting the sentiment of the reviews is a form of supervised machine learning. To be more specific, we will be using classification models for solving the problem of hate speech detection. We will be building an automated hate speech classification system in subsequent sections. The major steps to achieve this are mentioned as follows.\n",
    "\n",
    "+ Prepare train and test datasets (optionally a validation dataset)\n",
    "+ Pre-process and normalize text documents\n",
    "+ Feature Engineering \n",
    "+ Model training\n",
    "+ Model prediction and evaluation\n",
    "\n",
    "These are the major steps for building our system. Optionally the last step would be to deploy the model in your server or on the cloud. \n",
    "\n",
    "We will build models using deep learning in the subsequent sections. Our focus will be on Convolutional Neural Networks and Long Short Term Memory (LSTM) Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zJCWx7KtDzMW"
   },
   "source": [
    "## Load Dataset - Hate Speech\n",
    "\n",
    "Social media unfortunately is rampant with hate speech in the form of posts and comments. This is a practical example of perhaps building an automated hate speech detection system using NLP in the form of text classification.\n",
    "\n",
    "In this notebook, we will leverage an open sourced collection of hate speech posts and comments.\n",
    "\n",
    "The dataset is available here: [kaggle](https://www.kaggle.com/usharengaraju/dynamically-generated-hate-speech-dataset) which in turn has been curated from a wider [data source for hate speech](https://hatespeechdata.com/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bewz83RZKRes",
    "outputId": "9ff05668-e3db-4a15-ac84-64ff20479d39"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Mar 19 06:25:38 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.56       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   40C    P0    28W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6uGofwLCepsw"
   },
   "source": [
    "## Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2XlMiHnJHsxE",
    "outputId": "f6963b25-6a43-46a5-8a81-c495db35e42f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting contractions\n",
      "  Downloading https://files.pythonhosted.org/packages/0a/04/d5e0bb9f2cef5d15616ebf68087a725c5dbdd71bd422bcfb35d709f98ce7/contractions-0.0.48-py2.py3-none-any.whl\n",
      "Collecting textsearch>=0.0.21\n",
      "  Downloading https://files.pythonhosted.org/packages/d3/fe/021d7d76961b5ceb9f8d022c4138461d83beff36c3938dc424586085e559/textsearch-0.0.21-py2.py3-none-any.whl\n",
      "Collecting pyahocorasick\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4a/92/b3c70b8cf2b76f7e3e8b7243d6f06f7cb3bab6ada237b1bce57604c5c519/pyahocorasick-1.4.1.tar.gz (321kB)\n",
      "\u001b[K     |████████████████████████████████| 327kB 13.3MB/s \n",
      "\u001b[?25hCollecting anyascii\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/09/c7/61370d9e3c349478e89a5554c1e5d9658e1e3116cc4f2528f568909ebdf1/anyascii-0.1.7-py3-none-any.whl (260kB)\n",
      "\u001b[K     |████████████████████████████████| 266kB 12.0MB/s \n",
      "\u001b[?25hBuilding wheels for collected packages: pyahocorasick\n",
      "  Building wheel for pyahocorasick (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pyahocorasick: filename=pyahocorasick-1.4.1-cp37-cp37m-linux_x86_64.whl size=85250 sha256=7d7c55d48f9504c0c9b930645b2b8184519e7c0685c6c60c8c79e87f977dd19b\n",
      "  Stored in directory: /root/.cache/pip/wheels/e4/ab/f7/cb39270df8f6126f3dd4c33d302357167086db460968cfc80c\n",
      "Successfully built pyahocorasick\n",
      "Installing collected packages: pyahocorasick, anyascii, textsearch, contractions\n",
      "Successfully installed anyascii-0.1.7 contractions-0.0.48 pyahocorasick-1.4.1 textsearch-0.0.21\n",
      "Requirement already satisfied: textsearch in /usr/local/lib/python3.7/dist-packages (0.0.21)\n",
      "Requirement already satisfied: pyahocorasick in /usr/local/lib/python3.7/dist-packages (from textsearch) (1.4.1)\n",
      "Requirement already satisfied: anyascii in /usr/local/lib/python3.7/dist-packages (from textsearch) (0.1.7)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.41.1)\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install contractions\n",
    "!pip install textsearch\n",
    "!pip install tqdm\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4L3atJA0esmK"
   },
   "source": [
    "## Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "efwursaSIhrT"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Conv1D\n",
    "from tensorflow.keras.layers import MaxPooling1D\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow as tf\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 42\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lR47JCEPeu1I"
   },
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O04npo0tDGfT",
    "outputId": "23560673-ba1e-42c9-cc69-caccc7c9c197"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7523 entries, 0 to 7522\n",
      "Data columns (total 11 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Unnamed: 0      7523 non-null   int64  \n",
      " 1   id              7523 non-null   object \n",
      " 2   text            7523 non-null   object \n",
      " 3   label           7523 non-null   object \n",
      " 4   type            7523 non-null   object \n",
      " 5   model_wrong     6773 non-null   object \n",
      " 6   db.model_preds  6773 non-null   float64\n",
      " 7   status          7523 non-null   object \n",
      " 8   round           7523 non-null   object \n",
      " 9   split           7523 non-null   object \n",
      " 10  annotator       7522 non-null   object \n",
      "dtypes: float64(1), int64(1), object(9)\n",
      "memory usage: 646.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('HateDataset.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 198
    },
    "id": "D1WBdc_iD3lK",
    "outputId": "dcfd69ca-82d2-452b-d436-c9a3c2358205"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It should be legal for a husband to rape his wife</td>\n",
       "      <td>hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dalits are lowlife scum</td>\n",
       "      <td>hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dalits are lowlives</td>\n",
       "      <td>hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It was a better world when women dare not ques...</td>\n",
       "      <td>hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I don't work this hard so that those immigrant...</td>\n",
       "      <td>hate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text label\n",
       "0  It should be legal for a husband to rape his wife  hate\n",
       "1                            dalits are lowlife scum  hate\n",
       "2                                dalits are lowlives  hate\n",
       "3  It was a better world when women dare not ques...  hate\n",
       "4  I don't work this hard so that those immigrant...  hate"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[['text', 'label']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6UHDApkUezgs"
   },
   "source": [
    "## Prepare Train-Test Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "tUTXf8-HD3iw"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "jp5IPNc-D3f6"
   },
   "outputs": [],
   "source": [
    "train_reviews, test_reviews, train_labels, test_labels = train_test_split(df.text.values,\n",
    "                                                                          df.label.values,\n",
    "                                                                          test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0JGiBfQTD3bq",
    "outputId": "d6898eeb-9b9e-47f2-ef8a-aa39f11a1e62"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6018, 1505)"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_reviews), len(test_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-KLJnWc_e2gP"
   },
   "source": [
    "## Text Preprocessing : Text Wrangling and Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "3Ma4nPQGD3ZK"
   },
   "outputs": [],
   "source": [
    "import contractions\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import re\n",
    "import tqdm\n",
    "import unicodedata\n",
    "\n",
    "\n",
    "def strip_html_tags(text):\n",
    "  soup = BeautifulSoup(text, \"html.parser\")\n",
    "  [s.extract() for s in soup(['iframe', 'script'])]\n",
    "  stripped_text = soup.get_text()\n",
    "  stripped_text = re.sub(r'[\\r|\\n|\\r\\n]+', '\\n', stripped_text)\n",
    "  return stripped_text\n",
    "\n",
    "def remove_accented_chars(text):\n",
    "  text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "  return text\n",
    "\n",
    "def pre_process_corpus(docs):\n",
    "  norm_docs = []\n",
    "  for doc in tqdm.tqdm(docs):\n",
    "    doc = strip_html_tags(doc)\n",
    "    doc = doc.translate(doc.maketrans(\"\\n\\t\\r\", \"   \"))\n",
    "    doc = doc.lower()\n",
    "    doc = remove_accented_chars(doc)\n",
    "    doc = contractions.fix(doc)\n",
    "    # lower case and remove special characters\\whitespaces\n",
    "    doc = re.sub(r'[^a-zA-Z0-9\\s]', '', doc, flags=re.I|re.A)\n",
    "    doc = re.sub(' +', ' ', doc)\n",
    "    doc = doc.strip()  \n",
    "    norm_docs.append(doc)\n",
    "  \n",
    "  return norm_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mINWH1mrEK4t",
    "outputId": "edc79a8b-3949-4c80-ffb6-187a99e3870f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6018/6018 [00:00<00:00, 10495.99it/s]\n",
      "100%|██████████| 1505/1505 [00:00<00:00, 10709.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 655 ms, sys: 61.8 ms, total: 716 ms\n",
      "Wall time: 720 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "norm_train_reviews = pre_process_corpus(train_reviews)\n",
    "norm_test_reviews = pre_process_corpus(test_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XwkW6PKNe8-D"
   },
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "Tb_5TsxHINbV"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dropout, Activation, Dense\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "m20tOiQaEK2V"
   },
   "outputs": [],
   "source": [
    "t = Tokenizer(oov_token='<UNK>')\n",
    "# fit the tokenizer on the documents\n",
    "t.fit_on_texts(norm_train_reviews)\n",
    "t.word_index['<PAD>'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "x689E7FNERe1"
   },
   "outputs": [],
   "source": [
    "# transform train set using the tokenizer\n",
    "train_sequences = t.texts_to_sequences(norm_train_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "f69qradXERbx"
   },
   "outputs": [],
   "source": [
    "# transform test set using the tokenizer\n",
    "test_sequences = t.texts_to_sequences(norm_test_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dhRqmkRzERY2",
    "outputId": "b45f0ebd-3561-49da-e475-ff2680315a85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size=4126\n",
      "Number of Documents=6018\n"
     ]
    }
   ],
   "source": [
    "print(\"Vocabulary size={}\".format(len(t.word_index)))\n",
    "print(\"Number of Documents={}\".format(t.document_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sCNf9sOBfA1p"
   },
   "source": [
    "### Visualize Document Lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "id": "yb3eo4ZQERWG",
    "outputId": "dc85905b-bc24-48f8-e03b-d5691f447a11"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "train_lens = [len(s) for s in train_sequences]\n",
    "test_lens = [len(s) for s in test_sequences]\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize=(12, 6))\n",
    "h1 = ax[0].hist(train_lens)\n",
    "h2 = ax[1].hist(test_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "boygAGGZEdQO"
   },
   "outputs": [],
   "source": [
    "# while 250 is long should be a safe bet\n",
    "MAX_SEQUENCE_LENGTH = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4_DyPru-EdNe",
    "outputId": "8f7bb349-acd0-4aee-e7b7-59d53a181d3c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6018, 250), (1505, 250))"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pad dataset to a maximum review length in words\n",
    "X_train = sequence.pad_sequences(train_sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "X_test = sequence.pad_sequences(test_sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-8GNlovOfUmn"
   },
   "source": [
    "## Label Encode Class Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "AgFt61YFEdK-"
   },
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "# positive -> 1, negative -> 0\n",
    "num_classes=2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "PWlngiQnEk7d"
   },
   "outputs": [],
   "source": [
    "y_train = le.fit_transform(train_labels)\n",
    "y_test = le.transform(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "f5x8DAD9Ek4M"
   },
   "outputs": [],
   "source": [
    "VOCAB_SIZE = len(t.word_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SHUYJ2CRfW08"
   },
   "source": [
    "## **Question 1**:  Build and Train a CNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W086eML8gbLt"
   },
   "source": [
    "**Define** a Convolutional Neural Network such as it has:\n",
    "\n",
    "+ An embedding layer with embedding size of 300\n",
    "+ 3 pairs of Convolutional-1d and Maxpooling layer pairs\n",
    "+ Dense layers \n",
    "+ Choose an appropriate loss function and activation function for the final layer\n",
    "\n",
    "_Hint: Use a similar config as the tutorial and if you have more time feel free to play around with the layers and necessary hyperparameters_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "GMsWeJDEEk1p"
   },
   "outputs": [],
   "source": [
    "EMBED_SIZE = 300\n",
    "EPOCHS=10\n",
    "BATCH_SIZE=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p8EtBClQEdIO",
    "outputId": "5deee293-b1bc-4a4a-86fc-f61c814a4070"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 250, 300)          1237800   \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 250, 128)          153728    \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 125, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 125, 64)           32832     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 62, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 62, 32)            8224      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 31, 32)            0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 992)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               254208    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 1,687,049\n",
      "Trainable params: 1,687,049\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(VOCAB_SIZE, EMBED_SIZE, input_length=MAX_SEQUENCE_LENGTH))\n",
    "model.add(Conv1D(filters=128, kernel_size=4, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Conv1D(filters=64, kernel_size=4, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Conv1D(filters=32, kernel_size=4, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MUB7pKSWfqbd"
   },
   "source": [
    "## Train the CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j_lydJPtEqYh",
    "outputId": "d38ac747-0630-4318-afb9-48b65319e693"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "43/43 [==============================] - 18s 47ms/step - loss: 0.6344 - accuracy: 0.6094 - val_loss: 0.3230 - val_accuracy: 0.8688\n",
      "Epoch 2/10\n",
      "43/43 [==============================] - 2s 39ms/step - loss: 0.2524 - accuracy: 0.9026 - val_loss: 0.2776 - val_accuracy: 0.8804\n",
      "Epoch 3/10\n",
      "43/43 [==============================] - 2s 39ms/step - loss: 0.1044 - accuracy: 0.9661 - val_loss: 0.3126 - val_accuracy: 0.8854\n",
      "Epoch 4/10\n",
      "43/43 [==============================] - 2s 39ms/step - loss: 0.0535 - accuracy: 0.9828 - val_loss: 0.4507 - val_accuracy: 0.8804\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00004: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f77a65ead50>"
      ]
     },
     "execution_count": 29,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# callbacks\n",
    "es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                      patience=2,\n",
    "                                      restore_best_weights=True,\n",
    "                                      verbose=1)\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train, \n",
    "          validation_split=0.1,\n",
    "          epochs=EPOCHS, \n",
    "          batch_size=BATCH_SIZE,\n",
    "          callbacks=[es], \n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SLRZcLvfwaT"
   },
   "source": [
    "## Evaluate CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P_UtsqdeEqS1",
    "outputId": "209813d1-0d84-4ee6-a1c0-52b428f5bca2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 0, 0, 0, 0, 1, 1], dtype=int32)"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict_classes(X_test).ravel()\n",
    "predictions[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dPPS3EyCEyvr",
    "outputId": "9cd929bb-e569-49d7-dfba-393189794ac4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict_classes(X_test).ravel()\n",
    "predictions = le.inverse_transform(y_pred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 264
    },
    "id": "puPXT6Z9EytO",
    "outputId": "87a59dc0-ad44-4576-e32f-4e33f099cad9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        hate       0.90      0.89      0.89       900\n",
      "     nothate       0.84      0.84      0.84       605\n",
      "\n",
      "    accuracy                           0.87      1505\n",
      "   macro avg       0.87      0.87      0.87      1505\n",
      "weighted avg       0.87      0.87      0.87      1505\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hate</th>\n",
       "      <th>nothate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>hate</th>\n",
       "      <td>802</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nothate</th>\n",
       "      <td>94</td>\n",
       "      <td>511</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         hate  nothate\n",
       "hate      802       98\n",
       "nothate    94      511"
      ]
     },
     "execution_count": 33,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "labels = le.classes_.tolist()\n",
    "# print classification report\n",
    "print(classification_report(test_labels, predictions))\n",
    "# display confusion matrix\n",
    "pd.DataFrame(confusion_matrix(test_labels, predictions), index=labels, columns=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l7A4FWMvFHjf"
   },
   "source": [
    "## **Question 2**: Build and Train a LSTM based Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MHU35ZsthCNt"
   },
   "source": [
    "### **Define** a LSTM based Neural Network such as it has:\n",
    "\n",
    "+ An embedding layer with embedding size of 300\n",
    "+ An LSTM layer\n",
    "+ Dense layers \n",
    "+ Choose an appropriate loss function and activation function for the final layer\n",
    "\n",
    "_Hint: Use a similar config as the tutorial and if you have more time feel free to play around with the layers and necessary hyperparameters_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8rpzmY-0EyqS",
    "outputId": "9966ad02-cfec-4396-a0d6-152cec96aeaf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 250, 300)          1237800   \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d (SpatialDr (None, 250, 300)          0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 128)               219648    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 1,490,729\n",
      "Trainable params: 1,490,729\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_DIM = 300 # dimension for dense embeddings for each token\n",
    "LSTM_DIM = 128 # total LSTM units\n",
    "\n",
    "model2 = tf.keras.models.Sequential()\n",
    "model2.add(tf.keras.layers.Embedding(input_dim=VOCAB_SIZE, output_dim=EMBEDDING_DIM, input_length=MAX_SEQUENCE_LENGTH))\n",
    "model2.add(tf.keras.layers.SpatialDropout1D(0.1))\n",
    "model2.add(tf.keras.layers.LSTM(LSTM_DIM, return_sequences=False))\n",
    "model2.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "model2.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "model2.compile(loss=\"binary_crossentropy\", optimizer=\"adam\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cuU4D5zgf3uZ"
   },
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H1bet1IxEqQF",
    "outputId": "aa1df427-e5a2-4f93-d96a-6a06bb049c52"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "43/43 [==============================] - 4s 60ms/step - loss: 0.6097 - accuracy: 0.6397 - val_loss: 0.3177 - val_accuracy: 0.8588\n",
      "Epoch 2/10\n",
      "43/43 [==============================] - 2s 48ms/step - loss: 0.2339 - accuracy: 0.9064 - val_loss: 0.2981 - val_accuracy: 0.8688\n",
      "Epoch 3/10\n",
      "43/43 [==============================] - 2s 48ms/step - loss: 0.1397 - accuracy: 0.9470 - val_loss: 0.3130 - val_accuracy: 0.8721\n",
      "Epoch 4/10\n",
      "43/43 [==============================] - 2s 48ms/step - loss: 0.0891 - accuracy: 0.9688 - val_loss: 0.3978 - val_accuracy: 0.8605\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00004: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f775813c8d0>"
      ]
     },
     "execution_count": 35,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 128\n",
    "EPOCHS = 10\n",
    "\n",
    "es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                      patience=2,\n",
    "                                      restore_best_weights=True,\n",
    "                                      verbose=1)\n",
    "\n",
    "model2.fit(X_train, y_train, epochs=EPOCHS, batch_size=batch_size, \n",
    "          callbacks=[es],\n",
    "          shuffle=True, validation_split=0.1, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fuicIEN9gAnu"
   },
   "source": [
    "## Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Cz7t6i3mFMSF",
    "outputId": "c4b12abf-92df-4bd6-e918-08a02f70fd49"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 0, 0, 0, 0, 1, 1], dtype=int32)"
      ]
     },
     "execution_count": 36,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model2.predict_classes(X_test).ravel()\n",
    "predictions[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1h8UsbbfFMPt",
    "outputId": "c7591344-79b7-45ed-b3f6-5b0b2f97e7c7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "y_pred = model2.predict_classes(X_test).ravel()\n",
    "predictions = le.inverse_transform(y_pred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 264
    },
    "id": "UVnkwL_tFPvE",
    "outputId": "b609c9a7-1215-4af0-cc51-80c25428dd5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        hate       0.90      0.88      0.89       900\n",
      "     nothate       0.83      0.85      0.84       605\n",
      "\n",
      "    accuracy                           0.87      1505\n",
      "   macro avg       0.87      0.87      0.87      1505\n",
      "weighted avg       0.87      0.87      0.87      1505\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hate</th>\n",
       "      <th>nothate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>hate</th>\n",
       "      <td>796</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nothate</th>\n",
       "      <td>90</td>\n",
       "      <td>515</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         hate  nothate\n",
       "hate      796      104\n",
       "nothate    90      515"
      ]
     },
     "execution_count": 38,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = le.classes_.tolist()\n",
    "# print classification report\n",
    "print(classification_report(test_labels, predictions))\n",
    "# display confusion matrix\n",
    "pd.DataFrame(confusion_matrix(test_labels, predictions), index=labels, columns=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wf7El-JHFYOE"
   },
   "source": [
    "## **Question 3**: Build and Train a Bi-LSTM based Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2TetfCeIhaiD"
   },
   "source": [
    "### **Define** a Bi-Directional LSTM based Neural Network such as it has:\n",
    "\n",
    "+ An embedding layer with embedding size of 300\n",
    "+ 2 bi-directional LSTM layers (hint: remeber how to use ``return sequences``)\n",
    "+ Dense and Dropout layers \n",
    "+ Choose an appropriate loss function and activation function for the final layer\n",
    "\n",
    "_Hint: Use a similar config as the tutorial and if you have more time feel free to play around with the layers and necessary hyperparameters_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2IUSD4ipFYA6",
    "outputId": "aaed6032-41a6-47dc-81af-9325139f6849"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 250)]             0         \n",
      "_________________________________________________________________\n",
      "embedding_2 (Embedding)      (None, 250, 300)          1237800   \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 250, 256)          439296    \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 256)               394240    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,203,177\n",
      "Trainable params: 2,203,177\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_DIM = 300 # dimension for dense embeddings for each token\n",
    "LSTM_DIM = 128 # total LSTM units\n",
    "\n",
    "inp = tf.keras.layers.Input(shape=(MAX_SEQUENCE_LENGTH,))\n",
    "x = tf.keras.layers.Embedding(VOCAB_SIZE, EMBEDDING_DIM, trainable=True)(inp)\n",
    "x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(LSTM_DIM, return_sequences=True))(x)\n",
    "x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(LSTM_DIM, return_sequences=False))(x)\n",
    "x = tf.keras.layers.Dense(256, activation='relu')(x)\n",
    "x = tf.keras.layers.Dropout(rate=0.2)(x)\n",
    "x = tf.keras.layers.Dense(256, activation='relu')(x)\n",
    "x = tf.keras.layers.Dropout(rate=0.2)(x)\n",
    "\n",
    "outp = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "# initialize the model\n",
    "model3 = tf.keras.models.Model(inputs=inp, outputs=outp)\n",
    "\n",
    "    \n",
    "model3.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(), metrics=['accuracy'])\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0UTtZl0DgK0B"
   },
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "awZwcqhdFX-t",
    "outputId": "3dbfe0f8-7ad1-4df9-e32a-f2b183acf6c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "55/55 [==============================] - 12s 129ms/step - loss: 0.6005 - accuracy: 0.6692 - val_loss: 0.3276 - val_accuracy: 0.8571\n",
      "Epoch 2/5\n",
      "55/55 [==============================] - 6s 110ms/step - loss: 0.2280 - accuracy: 0.9101 - val_loss: 0.2915 - val_accuracy: 0.8704\n",
      "Epoch 3/5\n",
      "55/55 [==============================] - 6s 110ms/step - loss: 0.1238 - accuracy: 0.9577 - val_loss: 0.3177 - val_accuracy: 0.8804\n",
      "Epoch 4/5\n",
      "55/55 [==============================] - 6s 109ms/step - loss: 0.0755 - accuracy: 0.9732 - val_loss: 0.3609 - val_accuracy: 0.8804\n",
      "Epoch 5/5\n",
      "55/55 [==============================] - 6s 109ms/step - loss: 0.0492 - accuracy: 0.9817 - val_loss: 0.4769 - val_accuracy: 0.8821\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f76ce0da450>"
      ]
     },
     "execution_count": 40,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 100\n",
    "model3.fit(X_train, y_train, epochs=5, batch_size=batch_size, \n",
    "           shuffle=True, validation_split=0.1, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uTKxqKQrgNc8"
   },
   "source": [
    "## Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0S5PQfMOFX6C",
    "outputId": "fbb81786-802f-4a6f-b642-7e2286848381"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 2s 22ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0, 1, 0, 1, 0, 0, 0, 0, 1, 1]"
      ]
     },
     "execution_count": 41,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_probs = model3.predict(X_test, verbose=1).ravel()\n",
    "predictions = [1 if prob > 0.5 else 0 for prob in prediction_probs]\n",
    "predictions[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "giw5VThBFX3O",
    "outputId": "6fc08670-ae3d-4a98-e48d-32f65e41be8f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "y_pred = model3.predict_classes(X_test).ravel()\n",
    "predictions = le.inverse_transform(y_pred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 264
    },
    "id": "CaHN5OwpFXzk",
    "outputId": "37999c19-5429-4fda-931b-3e2eeef70eb9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        hate       0.90      0.89      0.89       900\n",
      "     nothate       0.84      0.84      0.84       605\n",
      "\n",
      "    accuracy                           0.87      1505\n",
      "   macro avg       0.87      0.87      0.87      1505\n",
      "weighted avg       0.87      0.87      0.87      1505\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hate</th>\n",
       "      <th>nothate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>hate</th>\n",
       "      <td>802</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nothate</th>\n",
       "      <td>94</td>\n",
       "      <td>511</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         hate  nothate\n",
       "hate      802       98\n",
       "nothate    94      511"
      ]
     },
     "execution_count": 43,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = le.classes_.tolist()\n",
    "# print classification report\n",
    "print(classification_report(test_labels, predictions))\n",
    "# display confusion matrix\n",
    "pd.DataFrame(confusion_matrix(test_labels, predictions), index=labels, columns=labels)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Exercise 1 - Text Classification using CNNs, LSTMs and Bi-Directional LSTMs - Solutions.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
