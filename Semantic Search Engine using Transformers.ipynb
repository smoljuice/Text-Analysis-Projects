{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8w2MPbHppeO0"
   },
   "source": [
    "# Building a Semantic Search Engine to Search for Queries with Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fb75SQP5pro_"
   },
   "source": [
    "# Semantic Search\n",
    "Semantic search seeks to improve search accuracy by understanding the content of the search query. In contrast to traditional search engines, that only finds documents based on lexical matches, semantic search can also find synonyms.\n",
    "\n",
    "\n",
    "## Background\n",
    "The idea behind semantic search is to embedd all entries in your corpus, which can be sentences, paragraphs, or documents, into a vector space. \n",
    "\n",
    "At search time, the query is embedded into the same vector space and the closest embedding from your corpus are found. These entries should have a high semantic overlap with the query.\n",
    "\n",
    "![SemanticSearch](https://raw.githubusercontent.com/UKPLab/sentence-transformers/master/docs/img/SemanticSearch.png) \n",
    "\n",
    "\n",
    "## Similarity Computation\n",
    "\n",
    "For small corpora (up to about 100k entries) we can compute the cosine-similarity between the query and all entries in the corpus.\n",
    "\n",
    "For small corpora with few example sentences we compute the embeddings for the corpus as well as for our query.\n",
    "\n",
    "We then use the [util.pytorch_cos_sim()](../../../docs/usage/semantic_textual_similarity.md) function to compute the cosine similarity between the query and all corpus entries.\n",
    "\n",
    "For large corpora, sorting all scores would take too much time. Hence, we can use [torch.topk](https://pytorch.org/docs/stable/generated/torch.topk.html) to only get the top k entries.\n",
    "\n",
    "[Reference](https://github.com/UKPLab/sentence-transformers/tree/master/examples/applications/semantic-search)\n",
    "\n",
    "\n",
    "## Objective\n",
    "\n",
    "For today's objective we will create a corpus of around 50000 question titles asked on Quora from an open dataset. Your task will be to compute sentence embeddings and then try to retrieve top 5 similar questions from the corpus for a few example queries mentioned below.\n",
    "\n",
    "Use [Sentence Transformers](https://github.com/UKPLab/sentence-transformers) which provides a scalable way to generate document embeddings using transformers\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "637DLY-vqofj"
   },
   "source": [
    "## Load Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1G6XYAOjKfoe",
    "outputId": "86b47608-374e-47b6-bda2-68069adec936"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ed/d5/f4157a376b8a79489a76ce6cfe147f4f3be1e029b7144fa7b8432e8acb26/transformers-4.4.2-py3-none-any.whl (2.0MB)\n",
      "\u001b[K     |████████████████████████████████| 2.0MB 4.3MB/s \n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
      "Collecting sacremoses\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
      "\u001b[K     |████████████████████████████████| 890kB 17.6MB/s \n",
      "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.1)\n",
      "Collecting tokenizers<0.11,>=0.10.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/23/2ddc317b2121117bf34dd00f5b0de194158f2a44ee2bf5e47c7166878a97/tokenizers-0.10.1-cp37-cp37m-manylinux2010_x86_64.whl (3.2MB)\n",
      "\u001b[K     |████████████████████████████████| 3.2MB 25.4MB/s \n",
      "\u001b[?25hRequirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
      "Building wheels for collected packages: sacremoses\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp37-none-any.whl size=893262 sha256=03c242430e750485a0997bf7a8b4cc75819599bc262987aac1fdbda00863874a\n",
      "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
      "Successfully built sacremoses\n",
      "Installing collected packages: sacremoses, tokenizers, transformers\n",
      "Successfully installed sacremoses-0.0.43 tokenizers-0.10.1 transformers-4.4.2\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-4Gb28zvKmfb",
    "outputId": "61788011-b50a-4655-8304-a8310646995e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/35/aa/f672ce489063c4ee7a566ebac1b723c53ac0cea19d9e36599cc241d8ed56/sentence-transformers-1.0.4.tar.gz (74kB)\n",
      "\r",
      "\u001b[K     |████▍                           | 10kB 17.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████▊                       | 20kB 20.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▏                  | 30kB 10.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▌              | 40kB 8.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▉          | 51kB 4.1MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▎     | 61kB 4.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▋ | 71kB 4.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 81kB 3.9MB/s \n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: transformers<5.0.0,>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (4.4.2)\n",
      "Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (4.41.1)\n",
      "Requirement already satisfied, skipping upgrade: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.8.1+cu101)\n",
      "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.19.5)\n",
      "Requirement already satisfied, skipping upgrade: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.22.2.post1)\n",
      "Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.4.1)\n",
      "Requirement already satisfied, skipping upgrade: nltk in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (3.2.5)\n",
      "Collecting sentencepiece\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2MB 7.3MB/s \n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (3.0.12)\n",
      "Requirement already satisfied, skipping upgrade: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (0.0.43)\n",
      "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (2.23.0)\n",
      "Requirement already satisfied, skipping upgrade: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (0.10.1)\n",
      "Requirement already satisfied, skipping upgrade: packaging in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (20.9)\n",
      "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (3.8.1)\n",
      "Requirement already satisfied, skipping upgrade: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (2019.12.20)\n",
      "Requirement already satisfied, skipping upgrade: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->sentence-transformers) (3.7.4.3)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sentence-transformers) (1.0.1)\n",
      "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.7/dist-packages (from nltk->sentence-transformers) (1.15.0)\n",
      "Requirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=3.1.0->sentence-transformers) (7.1.2)\n",
      "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (2.10)\n",
      "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (1.24.3)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (2020.12.5)\n",
      "Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers<5.0.0,>=3.1.0->sentence-transformers) (2.4.7)\n",
      "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers<5.0.0,>=3.1.0->sentence-transformers) (3.4.1)\n",
      "Building wheels for collected packages: sentence-transformers\n",
      "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for sentence-transformers: filename=sentence_transformers-1.0.4-cp37-none-any.whl size=114307 sha256=66b85a202e87b4abdc9bb3a02b3761932791d5dea40beed631ef0b3ec7cf17df\n",
      "  Stored in directory: /root/.cache/pip/wheels/26/ea/89/d0d2e013d951b6d23270aa9ca4018b82632ab7cd933c331316\n",
      "Successfully built sentence-transformers\n",
      "Installing collected packages: sentencepiece, sentence-transformers\n",
      "Successfully installed sentence-transformers-1.0.4 sentencepiece-0.1.95\n"
     ]
    }
   ],
   "source": [
    "!pip install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "hZbso1ipKa2S"
   },
   "outputs": [],
   "source": [
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "uRSgF-ITKWL6"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qd9fnlmlqqxh"
   },
   "source": [
    "## Download and Load Corpus of Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O37SmvVPK4Q_",
    "outputId": "bdf0d62f-eb4c-4e8a-d196-a4467a4a5ce2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-04-02 17:46:22--  http://qim.fs.quoracdn.net/quora_duplicate_questions.tsv\n",
      "Resolving qim.fs.quoracdn.net (qim.fs.quoracdn.net)... 151.101.1.2, 151.101.65.2, 151.101.129.2, ...\n",
      "Connecting to qim.fs.quoracdn.net (qim.fs.quoracdn.net)|151.101.1.2|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 58176133 (55M) [text/tab-separated-values]\n",
      "Saving to: ‘quora_duplicate_questions.tsv’\n",
      "\n",
      "quora_duplicate_que 100%[===================>]  55.48M   105MB/s    in 0.5s    \n",
      "\n",
      "2021-04-02 17:46:31 (105 MB/s) - ‘quora_duplicate_questions.tsv’ saved [58176133/58176133]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget http://qim.fs.quoracdn.net/quora_duplicate_questions.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "Wz3j4m13KtaR",
    "outputId": "6c91998f-f975-4601-cd4b-19384f4b334a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  ...                                          question2 is_duplicate\n",
       "0   0     1  ...  What is the step by step guide to invest in sh...            0\n",
       "1   1     3  ...  What would happen if the Indian government sto...            0\n",
       "2   2     5  ...  How can Internet speed be increased by hacking...            0\n",
       "3   3     7  ...  Find the remainder when [math]23^{24}[/math] i...            0\n",
       "4   4     9  ...            Which fish would survive in salt water?            0\n",
       "\n",
       "[5 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('quora_duplicate_questions.tsv', sep='\\t').head(25000)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "R3AfKmnGLCFg"
   },
   "outputs": [],
   "source": [
    "corpus = df['question1'].tolist() + df['question2'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rKfVgMPELMvT",
    "outputId": "8a24df76-f529-4a4f-ccaf-6b310ab4bca5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8v-WQjCAqvd9"
   },
   "source": [
    "## Use Sentence Transformers and Generate Corpus Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KuwhkFevq1rm"
   },
   "source": [
    "__Hint:__ You can use this tutorial as a reference\n",
    "\n",
    "[Semantic Search Tutorial](https://github.com/UKPLab/sentence-transformers/blob/master/examples/applications/semantic-search/semantic_search.py)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ufWzsq6dt4vI"
   },
   "source": [
    "# __Question 1__: Load Pre-trained Embedder Model\n",
    "\n",
    "Load the __`roberta-large-nli-stsb-mean-tokens`__ model to generate embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "gf8Q7vV4LP3A"
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66,
     "referenced_widgets": [
      "984a27bfee4e4b84afab139b16bd721c",
      "44a3449a70c445c8bba9372097024681",
      "d0181cdd4ad049479adcc383b6cd2f81",
      "b2e464e988d840388815d9023617c5f3",
      "292d61ab48a341d18f202e7b6a244698",
      "daece5aafbac499cb06eeb0c1cdb4969",
      "46a391ccac724319b3e531493f0ee5f1",
      "3b6017f13fa14faf9cd0b57f9f724b44"
     ]
    },
    "id": "fJIxH70vL3L1",
    "outputId": "2955d45b-0d54-4977-e049-05d668b8251b"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "984a27bfee4e4b84afab139b16bd721c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1313952051.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = 'roberta-large-nli-stsb-mean-tokens'\n",
    "embedder = SentenceTransformer(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q1LzJrmbuOaW"
   },
   "source": [
    "# __Question 2__: Generate Corpus Embeddings\n",
    "\n",
    "Generate embeddings for each and every document using the pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "G27sHdxRPPri"
   },
   "outputs": [],
   "source": [
    "corpus_embeddings = embedder.encode(corpus, convert_to_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9NVNIPeRP0Uj",
    "outputId": "508b5206-2839-42be-e37e-deb381dbaaa9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50000, 1024])"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rJS9cPFkrJO_"
   },
   "source": [
    "# __Question 3__: Create a function to print top K similar sentences for a given query\n",
    "\n",
    "Use cosine similarity by leveraging the pytorch utility in `sentence_transformers` as depicted in the previously linked tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "zz4J-WCdP7uz"
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import util\n",
    "import torch\n",
    "\n",
    "def print_similar_sentences(query, model_embedder, corpus_embeddings, top_k):\n",
    "    \"\"\"\n",
    "      query: this should be your input query\n",
    "      model_embedder: this should be your embedding model (pre-trained model which you loaded earlier)\n",
    "      corpus_embeddings: this should hold the embeddings you generate for your corpus\n",
    "      top_k: the top k similar queries you should return\n",
    "    \"\"\"\n",
    "\n",
    "    query_embedding = model_embedder.encode(query, convert_to_tensor=True)\n",
    "    cos_scores = util.pytorch_cos_sim(query_embedding, corpus_embeddings)[0]\n",
    "    cos_scores = cos_scores.cpu()\n",
    "\n",
    "    #We use torch.topk to find the highest 5 scores\n",
    "    top_results = torch.topk(cos_scores, k=top_k)\n",
    "    print(\"\\n\\n======================\\n\\n\")\n",
    "    print(\"Query:\", query)\n",
    "    print(\"\\nTop 5 most similar sentences in corpus:\")\n",
    "\n",
    "    for score, idx in zip(top_results[0], top_results[1]):\n",
    "        print(corpus[idx], \"(Score: %.4f)\" % (score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZW53grWprO73"
   },
   "source": [
    "# __Question 4__: Perform Semantic Search on Sample Questions to get Similar Queries from the Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HGbnncfyQsC8",
    "outputId": "b3a25408-4d83-4852-cf2f-d4545316bfc4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: What is the step by step guide to invest\n",
      "\n",
      "Top 5 most similar sentences in corpus:\n",
      "What is the step by step guide to invest in share market? (Score: 0.8431)\n",
      "What are the best investment strategy for beginners? (Score: 0.7725)\n",
      "What are the ways to get an investment for startup? (Score: 0.7692)\n",
      "How do I invest in stock market? (Score: 0.7558)\n",
      "How much money will I need to start investing in stock market? (Score: 0.7447)\n"
     ]
    }
   ],
   "source": [
    "s = 'What is the step by step guide to invest'\n",
    "print_similar_sentences(query=s,\n",
    "                        model_embedder=embedder, \n",
    "                        corpus_embeddings=corpus_embeddings,\n",
    "                        top_k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OFlPlIERQ9xy",
    "outputId": "48179da2-d06b-491c-9f2d-98cda23c6ddf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: What is Data Science?\n",
      "\n",
      "Top 5 most similar sentences in corpus:\n",
      "What is data science (Score: 0.9840)\n",
      "What is actually a data science? (Score: 0.9609)\n",
      "What does a data scientist do? (Score: 0.8919)\n",
      "What is big data science? (Score: 0.8633)\n",
      "What is the difference between data science and data analysis? (Score: 0.7723)\n"
     ]
    }
   ],
   "source": [
    "s = 'What is Data Science?'\n",
    "print_similar_sentences(query=s, \n",
    "                        model_embedder=embedder, \n",
    "                        corpus_embeddings=corpus_embeddings,\n",
    "                        top_k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I1Sse303SloA",
    "outputId": "7c0219d9-f8d3-4739-c89c-2c7027778296"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: What is natural language processing?\n",
      "\n",
      "Top 5 most similar sentences in corpus:\n",
      "How does natural language processing work? (Score: 0.9242)\n",
      "Which are the best schools for studying natural language processing? (Score: 0.6843)\n",
      "What is the english word for \"अंत्योदय\"? (Score: 0.6685)\n",
      "What are natural numbers? (Score: 0.6590)\n",
      "Who owns Natural Factors? (Score: 0.6589)\n"
     ]
    }
   ],
   "source": [
    "s = 'What is natural language processing?'\n",
    "print_similar_sentences(query=s, \n",
    "                        model_embedder=embedder, \n",
    "                        corpus_embeddings=corpus_embeddings,\n",
    "                        top_k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yCaAX2L_S1FV",
    "outputId": "005e6b01-f4fd-44fa-bb7c-f1cf1b63f57c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: What is natural language processing?\n",
      "\n",
      "Top 5 most similar sentences in corpus:\n",
      "How does natural language processing work? (Score: 0.9242)\n",
      "Which are the best schools for studying natural language processing? (Score: 0.6843)\n",
      "What is the english word for \"अंत्योदय\"? (Score: 0.6685)\n",
      "What are natural numbers? (Score: 0.6590)\n",
      "Who owns Natural Factors? (Score: 0.6589)\n"
     ]
    }
   ],
   "source": [
    "s = 'What is natural language processing?'\n",
    "print_similar_sentences(query=s, \n",
    "                        model_embedder=embedder, \n",
    "                        corpus_embeddings=corpus_embeddings,\n",
    "                        top_k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yTaLBUMpS7lc",
    "outputId": "d494c9c5-8a7c-45ba-dbca-3467cacf4b7d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: Best Harry Potter Movie?\n",
      "\n",
      "Top 5 most similar sentences in corpus:\n",
      "Which Harry Potter movie is the best? (Score: 0.9560)\n",
      "Which is the best Harry Potter movie? (Score: 0.9456)\n",
      "Which is your favourite Harry Potter movie and why? (Score: 0.8769)\n",
      "Where were the Harry Potter movies shot? (Score: 0.8664)\n",
      "Where was Harry Potter filmed? (Score: 0.8336)\n"
     ]
    }
   ],
   "source": [
    "s = 'Best Harry Potter Movie?'\n",
    "print_similar_sentences(query=s, \n",
    "                        model_embedder=embedder, \n",
    "                        corpus_embeddings=corpus_embeddings,\n",
    "                        top_k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n5Vs1PWCTGJA",
    "outputId": "ab672539-3ce8-45a9-8c49-89e02b620653"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: What is the best smartphone?\n",
      "\n",
      "Top 5 most similar sentences in corpus:\n",
      "What are the best smartphones? (Score: 0.9829)\n",
      "What are the best smartphones? (Score: 0.9829)\n",
      "What is the best smartphone to date? (Score: 0.9759)\n",
      "What are the best Smartphones tech gadgets? (Score: 0.9262)\n",
      "Which is the best smartphone to buy now? (Score: 0.9253)\n"
     ]
    }
   ],
   "source": [
    "s = 'What is the best smartphone?'\n",
    "print_similar_sentences(query=s, \n",
    "                        model_embedder=embedder, \n",
    "                        corpus_embeddings=corpus_embeddings,\n",
    "                        top_k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9MxlFbsTaeT",
    "outputId": "2016b7eb-b686-4ed8-e354-baf7f1257c96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: What is the best starter pokemon?\n",
      "\n",
      "Top 5 most similar sentences in corpus:\n",
      "How do you choose the right starter pokemon in any game? (Score: 0.8680)\n",
      "What is the best Pokemon GO hack? (Score: 0.7935)\n",
      "Which set of starter Pokemon would you choose considering all generations and why? (Score: 0.7794)\n",
      "What are the best Pokemon hacks? (Score: 0.7574)\n",
      "Which Pokemon evolve with Shiny Stones? (Score: 0.7405)\n"
     ]
    }
   ],
   "source": [
    "s = 'What is the best starter pokemon?'\n",
    "print_similar_sentences(query=s, \n",
    "                        model_embedder=embedder, \n",
    "                        corpus_embeddings=corpus_embeddings,\n",
    "                        top_k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A5wrOme0Tqrg",
    "outputId": "d4d050b6-d1a6-46fa-dc24-6da1e30bd854"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: Batman or Superman?\n",
      "\n",
      "Top 5 most similar sentences in corpus:\n",
      "Why does Batman kill in Batman v Superman? (Score: 0.7654)\n",
      "What does Batman do? (Score: 0.7581)\n",
      "Is Batman insane? (Score: 0.7382)\n",
      "Superheroes: Who would win in a fight between Batman and the Flash? (Score: 0.7381)\n",
      "Who would win Batman vs Batman? (Score: 0.7156)\n"
     ]
    }
   ],
   "source": [
    "s = 'Batman or Superman?'\n",
    "print_similar_sentences(query=s, \n",
    "                        model_embedder=embedder, \n",
    "                        corpus_embeddings=corpus_embeddings,\n",
    "                        top_k=5)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Exercise 2 - Building a Semantic Search Engine with Transformers - Solutions.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "292d61ab48a341d18f202e7b6a244698": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "3b6017f13fa14faf9cd0b57f9f724b44": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "44a3449a70c445c8bba9372097024681": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "46a391ccac724319b3e531493f0ee5f1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "984a27bfee4e4b84afab139b16bd721c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d0181cdd4ad049479adcc383b6cd2f81",
       "IPY_MODEL_b2e464e988d840388815d9023617c5f3"
      ],
      "layout": "IPY_MODEL_44a3449a70c445c8bba9372097024681"
     }
    },
    "b2e464e988d840388815d9023617c5f3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3b6017f13fa14faf9cd0b57f9f724b44",
      "placeholder": "​",
      "style": "IPY_MODEL_46a391ccac724319b3e531493f0ee5f1",
      "value": " 1.31G/1.31G [02:50&lt;00:00, 7.72MB/s]"
     }
    },
    "d0181cdd4ad049479adcc383b6cd2f81": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_daece5aafbac499cb06eeb0c1cdb4969",
      "max": 1313952051,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_292d61ab48a341d18f202e7b6a244698",
      "value": 1313952051
     }
    },
    "daece5aafbac499cb06eeb0c1cdb4969": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
