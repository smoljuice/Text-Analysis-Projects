{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nu_-xIqcvbuO"
   },
   "source": [
    "# Exercise 1 - Movie Recommender System with FastText Embeddings\n",
    "\n",
    "## Text Similarity\n",
    "\n",
    "Recommender systems are one of the popular and most adopted applications of machine learning. They are typically used to recommend entities to users and these entites can be anything like products, movies, services and so on.\n",
    "\n",
    "Popular examples of recommendations include,\n",
    "\n",
    "- Amazon suggesting products on its website\n",
    "- Amazon Prime, Netflix, Hotstar recommending movies\\shows\n",
    "- YouTube recommending videos to watch\n",
    "\n",
    "Typically recommender systems can be implemented in three ways:\n",
    "\n",
    "- Simple Rule-based Recommenders: Typically based on specific global metrics and thresholds like movie popularity, global ratings etc.\n",
    "- Content-based Recommenders: This is based on providing similar entities based on a specific entity of interest. Content metadata can be used here like movie descriptions, genre, cast, director and so on\n",
    "- Collaborative filtering Recommenders: Here we don't need metadata but we try to predict recommendations and ratings based on past ratings of different users and specific items.\n",
    "\n",
    "__We will be building a movie recommendation system here where based on data\\metadata pertaining to different movies, we try and recommend similar movies of interest!__\n",
    "\n",
    "With this exercise we will learn how to apply concepts learnt through tutorials of week1. Let's get started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TS_vIju4vnQf"
   },
   "source": [
    "## Load Data\n",
    "\n",
    "If you are using google colab please use the upload file button option from the 'Files' icon on the left pane to upload the `tmdb_5000_movies.csv.gz` dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qr3XMWfJvMiG",
    "outputId": "fb0f98f2-214a-4cf7-82bd-fe13b694b012"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4803 entries, 0 to 4802\n",
      "Data columns (total 20 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   budget                4803 non-null   int64  \n",
      " 1   genres                4803 non-null   object \n",
      " 2   homepage              1712 non-null   object \n",
      " 3   id                    4803 non-null   int64  \n",
      " 4   keywords              4803 non-null   object \n",
      " 5   original_language     4803 non-null   object \n",
      " 6   original_title        4803 non-null   object \n",
      " 7   overview              4800 non-null   object \n",
      " 8   popularity            4803 non-null   float64\n",
      " 9   production_companies  4803 non-null   object \n",
      " 10  production_countries  4803 non-null   object \n",
      " 11  release_date          4802 non-null   object \n",
      " 12  revenue               4803 non-null   int64  \n",
      " 13  runtime               4801 non-null   float64\n",
      " 14  spoken_languages      4803 non-null   object \n",
      " 15  status                4803 non-null   object \n",
      " 16  tagline               3959 non-null   object \n",
      " 17  title                 4803 non-null   object \n",
      " 18  vote_average          4803 non-null   float64\n",
      " 19  vote_count            4803 non-null   int64  \n",
      "dtypes: float64(3), int64(4), object(13)\n",
      "memory usage: 750.6+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('tmdb_5000_movies.csv.gz', compression='gzip')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OPifQHRjvs7e"
   },
   "source": [
    "### **Question 1**: **View** top few rows of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 702
    },
    "id": "Hn0jo9IHvuGd",
    "outputId": "a14cbbf9-1cb1-4e05-9234-36561d2e044d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>budget</th>\n",
       "      <th>genres</th>\n",
       "      <th>homepage</th>\n",
       "      <th>id</th>\n",
       "      <th>keywords</th>\n",
       "      <th>original_language</th>\n",
       "      <th>original_title</th>\n",
       "      <th>overview</th>\n",
       "      <th>popularity</th>\n",
       "      <th>production_companies</th>\n",
       "      <th>production_countries</th>\n",
       "      <th>release_date</th>\n",
       "      <th>revenue</th>\n",
       "      <th>runtime</th>\n",
       "      <th>spoken_languages</th>\n",
       "      <th>status</th>\n",
       "      <th>tagline</th>\n",
       "      <th>title</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>237000000</td>\n",
       "      <td>[{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...</td>\n",
       "      <td>http://www.avatarmovie.com/</td>\n",
       "      <td>19995</td>\n",
       "      <td>[{\"id\": 1463, \"name\": \"culture clash\"}, {\"id\":...</td>\n",
       "      <td>en</td>\n",
       "      <td>Avatar</td>\n",
       "      <td>In the 22nd century, a paraplegic Marine is di...</td>\n",
       "      <td>150.437577</td>\n",
       "      <td>[{\"name\": \"Ingenious Film Partners\", \"id\": 289...</td>\n",
       "      <td>[{\"iso_3166_1\": \"US\", \"name\": \"United States o...</td>\n",
       "      <td>2009-12-10</td>\n",
       "      <td>2787965087</td>\n",
       "      <td>162.0</td>\n",
       "      <td>[{\"iso_639_1\": \"en\", \"name\": \"English\"}, {\"iso...</td>\n",
       "      <td>Released</td>\n",
       "      <td>Enter the World of Pandora.</td>\n",
       "      <td>Avatar</td>\n",
       "      <td>7.2</td>\n",
       "      <td>11800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>300000000</td>\n",
       "      <td>[{\"id\": 12, \"name\": \"Adventure\"}, {\"id\": 14, \"...</td>\n",
       "      <td>http://disney.go.com/disneypictures/pirates/</td>\n",
       "      <td>285</td>\n",
       "      <td>[{\"id\": 270, \"name\": \"ocean\"}, {\"id\": 726, \"na...</td>\n",
       "      <td>en</td>\n",
       "      <td>Pirates of the Caribbean: At World's End</td>\n",
       "      <td>Captain Barbossa, long believed to be dead, ha...</td>\n",
       "      <td>139.082615</td>\n",
       "      <td>[{\"name\": \"Walt Disney Pictures\", \"id\": 2}, {\"...</td>\n",
       "      <td>[{\"iso_3166_1\": \"US\", \"name\": \"United States o...</td>\n",
       "      <td>2007-05-19</td>\n",
       "      <td>961000000</td>\n",
       "      <td>169.0</td>\n",
       "      <td>[{\"iso_639_1\": \"en\", \"name\": \"English\"}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>At the end of the world, the adventure begins.</td>\n",
       "      <td>Pirates of the Caribbean: At World's End</td>\n",
       "      <td>6.9</td>\n",
       "      <td>4500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>245000000</td>\n",
       "      <td>[{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...</td>\n",
       "      <td>http://www.sonypictures.com/movies/spectre/</td>\n",
       "      <td>206647</td>\n",
       "      <td>[{\"id\": 470, \"name\": \"spy\"}, {\"id\": 818, \"name...</td>\n",
       "      <td>en</td>\n",
       "      <td>Spectre</td>\n",
       "      <td>A cryptic message from Bondâ€™s past sends him o...</td>\n",
       "      <td>107.376788</td>\n",
       "      <td>[{\"name\": \"Columbia Pictures\", \"id\": 5}, {\"nam...</td>\n",
       "      <td>[{\"iso_3166_1\": \"GB\", \"name\": \"United Kingdom\"...</td>\n",
       "      <td>2015-10-26</td>\n",
       "      <td>880674609</td>\n",
       "      <td>148.0</td>\n",
       "      <td>[{\"iso_639_1\": \"fr\", \"name\": \"Fran\\u00e7ais\"},...</td>\n",
       "      <td>Released</td>\n",
       "      <td>A Plan No One Escapes</td>\n",
       "      <td>Spectre</td>\n",
       "      <td>6.3</td>\n",
       "      <td>4466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>250000000</td>\n",
       "      <td>[{\"id\": 28, \"name\": \"Action\"}, {\"id\": 80, \"nam...</td>\n",
       "      <td>http://www.thedarkknightrises.com/</td>\n",
       "      <td>49026</td>\n",
       "      <td>[{\"id\": 849, \"name\": \"dc comics\"}, {\"id\": 853,...</td>\n",
       "      <td>en</td>\n",
       "      <td>The Dark Knight Rises</td>\n",
       "      <td>Following the death of District Attorney Harve...</td>\n",
       "      <td>112.312950</td>\n",
       "      <td>[{\"name\": \"Legendary Pictures\", \"id\": 923}, {\"...</td>\n",
       "      <td>[{\"iso_3166_1\": \"US\", \"name\": \"United States o...</td>\n",
       "      <td>2012-07-16</td>\n",
       "      <td>1084939099</td>\n",
       "      <td>165.0</td>\n",
       "      <td>[{\"iso_639_1\": \"en\", \"name\": \"English\"}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>The Legend Ends</td>\n",
       "      <td>The Dark Knight Rises</td>\n",
       "      <td>7.6</td>\n",
       "      <td>9106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>260000000</td>\n",
       "      <td>[{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...</td>\n",
       "      <td>http://movies.disney.com/john-carter</td>\n",
       "      <td>49529</td>\n",
       "      <td>[{\"id\": 818, \"name\": \"based on novel\"}, {\"id\":...</td>\n",
       "      <td>en</td>\n",
       "      <td>John Carter</td>\n",
       "      <td>John Carter is a war-weary, former military ca...</td>\n",
       "      <td>43.926995</td>\n",
       "      <td>[{\"name\": \"Walt Disney Pictures\", \"id\": 2}]</td>\n",
       "      <td>[{\"iso_3166_1\": \"US\", \"name\": \"United States o...</td>\n",
       "      <td>2012-03-07</td>\n",
       "      <td>284139100</td>\n",
       "      <td>132.0</td>\n",
       "      <td>[{\"iso_639_1\": \"en\", \"name\": \"English\"}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>Lost in our world, found in another.</td>\n",
       "      <td>John Carter</td>\n",
       "      <td>6.1</td>\n",
       "      <td>2124</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      budget  ... vote_count\n",
       "0  237000000  ...      11800\n",
       "1  300000000  ...       4500\n",
       "2  245000000  ...       4466\n",
       "3  250000000  ...       9106\n",
       "4  260000000  ...       2124\n",
       "\n",
       "[5 rows x 20 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "5h2081STv040"
   },
   "outputs": [],
   "source": [
    "column_list = ['title', 'tagline', 'overview', 'genres', 'popularity']\n",
    "df = df[column_list]\n",
    "df.tagline.fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u8y8-6tdv3qu"
   },
   "source": [
    "### **Question 2**: Merge text from tagline column with text from overview column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "VdBq30zUv2-r"
   },
   "outputs": [],
   "source": [
    "df['description'] = df['tagline'].map(str) + ' ' + df['overview'].map(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9YWpp8jLv8Z2",
    "outputId": "b4feb933-30c6-4eab-fd73-a85a093d76ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4800 entries, 0 to 4802\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   title        4800 non-null   object \n",
      " 1   tagline      4800 non-null   object \n",
      " 2   overview     4800 non-null   object \n",
      " 3   genres       4800 non-null   object \n",
      " 4   popularity   4800 non-null   float64\n",
      " 5   description  4800 non-null   object \n",
      "dtypes: float64(1), object(5)\n",
      "memory usage: 262.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.dropna(inplace=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yU--WPKcwEBs"
   },
   "source": [
    "## Text Preprocessing\n",
    "\n",
    "First step is to prepare the text columns for analysis. In this section we will prepare textual columns before we extract features from them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "leKwVGhfv8XR"
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oBH6mrhEv8Ud",
    "outputId": "b25d8c49-5822-46c8-9a08-6fa92fce0503"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sQYjzqEnw9HH"
   },
   "source": [
    "### **Question 3**: Complete the text normalization utility function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "j42KNzQ8w-Bz"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "\n",
    "stop_words = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "cpco9Ed_w9_3"
   },
   "outputs": [],
   "source": [
    "def normalize_document(doc):\n",
    "    # remove special characters\\whitespaces, ignore case\n",
    "    doc = re.sub(r'[^a-zA-Z0-9\\s]', '', doc, re.I|re.A)\n",
    "\n",
    "    # lower case  \n",
    "    doc = doc.lower()\n",
    "\n",
    "    # remove whitespaces\n",
    "    doc = doc.strip()\n",
    "\n",
    "    # tokenize document\n",
    "    tokens = nltk.word_tokenize(doc)\n",
    "\n",
    "    # filter stopwords out of document\n",
    "    filtered_tokens = [token for token in tokens if token not in stop_words]\n",
    "\n",
    "    # re-create/merge sentences from filtered content\n",
    "    doc = ' '.join(filtered_tokens)\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2vzO416Aw99H",
    "outputId": "fce89e18-cc62-49b2-eaec-4f3d3c300170"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4800"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalize_corpus = np.vectorize(normalize_document)\n",
    "\n",
    "norm_corpus = normalize_corpus(list(df['description']))\n",
    "len(norm_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QcfdT6fyfreF",
    "outputId": "e7f0e3e8-d406-4419-fa31-587b8085767a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['Avatar', \"Pirates of the Caribbean: At World's End\", 'Spectre',\n",
       "        ..., 'Signed, Sealed, Delivered', 'Shanghai Calling',\n",
       "        'My Date with Drew'], dtype=object), (4800,))"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_list = df['title'].values\n",
    "movies_list, movies_list.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vJMe4XzPxk4S"
   },
   "source": [
    "## Movie Recommendation with Embeddings\n",
    "We used count based features in a similar assignment in the first course. Can we use word embeddings and then compute movie similarity? We definitely can! Here we will use the FastText model and train it on our corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r-uyv-bGxwrk"
   },
   "source": [
    "### **Question 4**: Use ``gensim`` to train a FastText model on the normalized corpus\n",
    "\n",
    "You can keep:\n",
    "\n",
    "- the embedding size to be 300\n",
    "- context to be around 30\n",
    "- min word count to be 2 (feel free to try more if needed as a filter)\n",
    "- use a skipgram model\n",
    "- iterations can be 50 (reduce it if it takes too long)\n",
    "\n",
    "This might take a while to train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "hOvj1gP2w9a4"
   },
   "outputs": [],
   "source": [
    "from gensim.models import FastText\n",
    "\n",
    "# iterate normalized corpus and split\n",
    "tokenized_docs = [doc.split() for doc in norm_corpus]\n",
    "\n",
    "# Set values for various parameters\n",
    "feature_size = 300   # Set Word embedding dimensionality \n",
    "window_context = 30  # Set Context window size                                                                                  \n",
    "min_word_count = 2   # Set Minimum word count                    \n",
    "sg = 1               # set skip-gram model flag\n",
    "\n",
    "# train FastText model\n",
    "ft_model = FastText(tokenized_docs, \n",
    "                    size=feature_size, \n",
    "                    window=window_context, \n",
    "                    min_count=min_word_count, \n",
    "                    sg=sg, \n",
    "                    iter=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nfuTtrMmx_2z"
   },
   "source": [
    "##Generate document level embeddings\n",
    "\n",
    "Word embedding models give us an embedding for each word, how can we use it for downstream ML\\DL tasks? one way is to flatten it or use sequential models. A simpler approach is to average all word embeddings for words in a document and generate a fixed-length document level emebdding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Art_yII9yEh4"
   },
   "source": [
    "### **Question 5**: Complete the following utility to prepare document vectors by averaging word vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "C-za9YDAyBld"
   },
   "outputs": [],
   "source": [
    "def averaged_word2vec_vectorizer(corpus, model, num_features):\n",
    "    vocabulary = set(model.wv.index2word)\n",
    "    \n",
    "    def average_word_vectors(words, model, vocabulary, num_features):\n",
    "        feature_vector = np.zeros((num_features,), dtype=\"float64\")\n",
    "        nwords = 0.\n",
    "        \n",
    "        for word in words:\n",
    "            if word in vocabulary: \n",
    "                nwords = nwords + 1.\n",
    "                feature_vector = np.add(feature_vector, model.wv[word])\n",
    "        if nwords:\n",
    "            feature_vector = np.divide(feature_vector, nwords)\n",
    "\n",
    "        return feature_vector\n",
    "\n",
    "    features = [average_word_vectors(tokenized_sentence, model, vocabulary, num_features)\n",
    "                    for tokenized_sentence in corpus]\n",
    "    return np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K-ikl1OGyPI2",
    "outputId": "872ed02c-40e6-4a36-c411-244bf8368758"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4800, 300)"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_vecs_ft = averaged_word2vec_vectorizer(tokenized_docs, ft_model, 300)\n",
    "doc_vecs_ft.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3vsnxIasySJc"
   },
   "source": [
    "## Get Movie Recommendations\n",
    "\n",
    "Recommendations in its most simplest form is a method of identifying items which are most similar to given user's preferences. In this scenario we use a content based recommendation system which tries to find similar movies based on the movie content i.e. description.\n",
    "\n",
    "To identify similar items, we will use pairwise similarity measure called **cosine similarity**\n",
    "\n",
    "We will leverage cosine similarity to generate recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iiDBoSmCyYpe"
   },
   "source": [
    "### **Question 6**: Complete the following snippet to prepare a dataframe of pair-wise cosine similarity of different movies\n",
    "\n",
    "Create pairwise cosine similarity based on the document embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "pkFdzkbw2KpN"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 244
    },
    "id": "VJ0OPwSKyT24",
    "outputId": "524f8496-6698-4470-a4d3-30f37746b328"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>...</th>\n",
       "      <th>4760</th>\n",
       "      <th>4761</th>\n",
       "      <th>4762</th>\n",
       "      <th>4763</th>\n",
       "      <th>4764</th>\n",
       "      <th>4765</th>\n",
       "      <th>4766</th>\n",
       "      <th>4767</th>\n",
       "      <th>4768</th>\n",
       "      <th>4769</th>\n",
       "      <th>4770</th>\n",
       "      <th>4771</th>\n",
       "      <th>4772</th>\n",
       "      <th>4773</th>\n",
       "      <th>4774</th>\n",
       "      <th>4775</th>\n",
       "      <th>4776</th>\n",
       "      <th>4777</th>\n",
       "      <th>4778</th>\n",
       "      <th>4779</th>\n",
       "      <th>4780</th>\n",
       "      <th>4781</th>\n",
       "      <th>4782</th>\n",
       "      <th>4783</th>\n",
       "      <th>4784</th>\n",
       "      <th>4785</th>\n",
       "      <th>4786</th>\n",
       "      <th>4787</th>\n",
       "      <th>4788</th>\n",
       "      <th>4789</th>\n",
       "      <th>4790</th>\n",
       "      <th>4791</th>\n",
       "      <th>4792</th>\n",
       "      <th>4793</th>\n",
       "      <th>4794</th>\n",
       "      <th>4795</th>\n",
       "      <th>4796</th>\n",
       "      <th>4797</th>\n",
       "      <th>4798</th>\n",
       "      <th>4799</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.543656</td>\n",
       "      <td>0.571502</td>\n",
       "      <td>0.576771</td>\n",
       "      <td>0.585465</td>\n",
       "      <td>0.514846</td>\n",
       "      <td>0.548100</td>\n",
       "      <td>0.593339</td>\n",
       "      <td>0.480626</td>\n",
       "      <td>0.555727</td>\n",
       "      <td>0.514425</td>\n",
       "      <td>0.529462</td>\n",
       "      <td>0.447749</td>\n",
       "      <td>0.469812</td>\n",
       "      <td>0.590477</td>\n",
       "      <td>0.509425</td>\n",
       "      <td>0.525093</td>\n",
       "      <td>0.521376</td>\n",
       "      <td>0.542951</td>\n",
       "      <td>0.520712</td>\n",
       "      <td>0.532792</td>\n",
       "      <td>0.509176</td>\n",
       "      <td>0.476910</td>\n",
       "      <td>0.453607</td>\n",
       "      <td>0.501605</td>\n",
       "      <td>0.487991</td>\n",
       "      <td>0.607755</td>\n",
       "      <td>0.647696</td>\n",
       "      <td>0.450206</td>\n",
       "      <td>0.589642</td>\n",
       "      <td>0.521750</td>\n",
       "      <td>0.561021</td>\n",
       "      <td>0.520540</td>\n",
       "      <td>0.504351</td>\n",
       "      <td>0.476670</td>\n",
       "      <td>0.570520</td>\n",
       "      <td>0.661068</td>\n",
       "      <td>0.424902</td>\n",
       "      <td>0.525810</td>\n",
       "      <td>0.522546</td>\n",
       "      <td>...</td>\n",
       "      <td>0.511775</td>\n",
       "      <td>0.509590</td>\n",
       "      <td>0.523163</td>\n",
       "      <td>0.462074</td>\n",
       "      <td>0.468663</td>\n",
       "      <td>0.437186</td>\n",
       "      <td>0.486310</td>\n",
       "      <td>0.498676</td>\n",
       "      <td>0.514734</td>\n",
       "      <td>0.522910</td>\n",
       "      <td>0.435219</td>\n",
       "      <td>0.556549</td>\n",
       "      <td>0.479761</td>\n",
       "      <td>0.517283</td>\n",
       "      <td>0.553285</td>\n",
       "      <td>0.506227</td>\n",
       "      <td>0.532386</td>\n",
       "      <td>0.533296</td>\n",
       "      <td>0.421123</td>\n",
       "      <td>0.537898</td>\n",
       "      <td>0.625770</td>\n",
       "      <td>0.512810</td>\n",
       "      <td>0.524349</td>\n",
       "      <td>0.496454</td>\n",
       "      <td>0.503480</td>\n",
       "      <td>0.470713</td>\n",
       "      <td>0.473932</td>\n",
       "      <td>0.403589</td>\n",
       "      <td>0.457871</td>\n",
       "      <td>0.520597</td>\n",
       "      <td>0.499712</td>\n",
       "      <td>0.485649</td>\n",
       "      <td>0.552020</td>\n",
       "      <td>0.574626</td>\n",
       "      <td>0.544143</td>\n",
       "      <td>0.480639</td>\n",
       "      <td>0.403255</td>\n",
       "      <td>0.536898</td>\n",
       "      <td>0.491150</td>\n",
       "      <td>0.506592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.543656</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.531973</td>\n",
       "      <td>0.526304</td>\n",
       "      <td>0.610740</td>\n",
       "      <td>0.541783</td>\n",
       "      <td>0.577951</td>\n",
       "      <td>0.605901</td>\n",
       "      <td>0.589881</td>\n",
       "      <td>0.576854</td>\n",
       "      <td>0.509377</td>\n",
       "      <td>0.534877</td>\n",
       "      <td>0.600052</td>\n",
       "      <td>0.575227</td>\n",
       "      <td>0.636577</td>\n",
       "      <td>0.633299</td>\n",
       "      <td>0.601086</td>\n",
       "      <td>0.645071</td>\n",
       "      <td>0.626382</td>\n",
       "      <td>0.541157</td>\n",
       "      <td>0.596385</td>\n",
       "      <td>0.558236</td>\n",
       "      <td>0.558060</td>\n",
       "      <td>0.602392</td>\n",
       "      <td>0.553261</td>\n",
       "      <td>0.619319</td>\n",
       "      <td>0.593906</td>\n",
       "      <td>0.637502</td>\n",
       "      <td>0.525238</td>\n",
       "      <td>0.553103</td>\n",
       "      <td>0.578348</td>\n",
       "      <td>0.560380</td>\n",
       "      <td>0.575687</td>\n",
       "      <td>0.497541</td>\n",
       "      <td>0.515530</td>\n",
       "      <td>0.578095</td>\n",
       "      <td>0.604730</td>\n",
       "      <td>0.610149</td>\n",
       "      <td>0.585717</td>\n",
       "      <td>0.549419</td>\n",
       "      <td>...</td>\n",
       "      <td>0.629926</td>\n",
       "      <td>0.550752</td>\n",
       "      <td>0.521691</td>\n",
       "      <td>0.537824</td>\n",
       "      <td>0.561665</td>\n",
       "      <td>0.532062</td>\n",
       "      <td>0.531339</td>\n",
       "      <td>0.518528</td>\n",
       "      <td>0.540151</td>\n",
       "      <td>0.577129</td>\n",
       "      <td>0.513090</td>\n",
       "      <td>0.470172</td>\n",
       "      <td>0.573096</td>\n",
       "      <td>0.540939</td>\n",
       "      <td>0.622705</td>\n",
       "      <td>0.562116</td>\n",
       "      <td>0.587132</td>\n",
       "      <td>0.534118</td>\n",
       "      <td>0.508154</td>\n",
       "      <td>0.606822</td>\n",
       "      <td>0.597617</td>\n",
       "      <td>0.609799</td>\n",
       "      <td>0.511232</td>\n",
       "      <td>0.553702</td>\n",
       "      <td>0.533357</td>\n",
       "      <td>0.505693</td>\n",
       "      <td>0.482825</td>\n",
       "      <td>0.474862</td>\n",
       "      <td>0.587907</td>\n",
       "      <td>0.533585</td>\n",
       "      <td>0.581166</td>\n",
       "      <td>0.535200</td>\n",
       "      <td>0.600071</td>\n",
       "      <td>0.557906</td>\n",
       "      <td>0.541416</td>\n",
       "      <td>0.554876</td>\n",
       "      <td>0.443544</td>\n",
       "      <td>0.598936</td>\n",
       "      <td>0.556741</td>\n",
       "      <td>0.554506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.571502</td>\n",
       "      <td>0.531973</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.580201</td>\n",
       "      <td>0.517781</td>\n",
       "      <td>0.529581</td>\n",
       "      <td>0.532595</td>\n",
       "      <td>0.596229</td>\n",
       "      <td>0.583240</td>\n",
       "      <td>0.565277</td>\n",
       "      <td>0.531609</td>\n",
       "      <td>0.724202</td>\n",
       "      <td>0.527497</td>\n",
       "      <td>0.546672</td>\n",
       "      <td>0.586876</td>\n",
       "      <td>0.534116</td>\n",
       "      <td>0.587137</td>\n",
       "      <td>0.606047</td>\n",
       "      <td>0.640868</td>\n",
       "      <td>0.570551</td>\n",
       "      <td>0.595836</td>\n",
       "      <td>0.527107</td>\n",
       "      <td>0.568406</td>\n",
       "      <td>0.557415</td>\n",
       "      <td>0.498409</td>\n",
       "      <td>0.494578</td>\n",
       "      <td>0.567184</td>\n",
       "      <td>0.560195</td>\n",
       "      <td>0.486927</td>\n",
       "      <td>0.713793</td>\n",
       "      <td>0.567058</td>\n",
       "      <td>0.575884</td>\n",
       "      <td>0.593751</td>\n",
       "      <td>0.550938</td>\n",
       "      <td>0.512813</td>\n",
       "      <td>0.664628</td>\n",
       "      <td>0.607573</td>\n",
       "      <td>0.548501</td>\n",
       "      <td>0.621753</td>\n",
       "      <td>0.563033</td>\n",
       "      <td>...</td>\n",
       "      <td>0.542687</td>\n",
       "      <td>0.592129</td>\n",
       "      <td>0.540951</td>\n",
       "      <td>0.489796</td>\n",
       "      <td>0.619029</td>\n",
       "      <td>0.480655</td>\n",
       "      <td>0.560138</td>\n",
       "      <td>0.505169</td>\n",
       "      <td>0.520780</td>\n",
       "      <td>0.585978</td>\n",
       "      <td>0.484433</td>\n",
       "      <td>0.483752</td>\n",
       "      <td>0.529018</td>\n",
       "      <td>0.530520</td>\n",
       "      <td>0.574858</td>\n",
       "      <td>0.582521</td>\n",
       "      <td>0.527885</td>\n",
       "      <td>0.569417</td>\n",
       "      <td>0.465710</td>\n",
       "      <td>0.559461</td>\n",
       "      <td>0.622671</td>\n",
       "      <td>0.522889</td>\n",
       "      <td>0.506316</td>\n",
       "      <td>0.547452</td>\n",
       "      <td>0.571032</td>\n",
       "      <td>0.568400</td>\n",
       "      <td>0.502715</td>\n",
       "      <td>0.490683</td>\n",
       "      <td>0.535784</td>\n",
       "      <td>0.565864</td>\n",
       "      <td>0.574146</td>\n",
       "      <td>0.478943</td>\n",
       "      <td>0.568461</td>\n",
       "      <td>0.549357</td>\n",
       "      <td>0.570718</td>\n",
       "      <td>0.520024</td>\n",
       "      <td>0.485759</td>\n",
       "      <td>0.535344</td>\n",
       "      <td>0.540606</td>\n",
       "      <td>0.519636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.576771</td>\n",
       "      <td>0.526304</td>\n",
       "      <td>0.580201</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.556169</td>\n",
       "      <td>0.532214</td>\n",
       "      <td>0.542953</td>\n",
       "      <td>0.601797</td>\n",
       "      <td>0.571174</td>\n",
       "      <td>0.701340</td>\n",
       "      <td>0.520844</td>\n",
       "      <td>0.573428</td>\n",
       "      <td>0.488400</td>\n",
       "      <td>0.566145</td>\n",
       "      <td>0.566526</td>\n",
       "      <td>0.508648</td>\n",
       "      <td>0.527558</td>\n",
       "      <td>0.533691</td>\n",
       "      <td>0.590783</td>\n",
       "      <td>0.536273</td>\n",
       "      <td>0.543300</td>\n",
       "      <td>0.560087</td>\n",
       "      <td>0.508397</td>\n",
       "      <td>0.497619</td>\n",
       "      <td>0.559591</td>\n",
       "      <td>0.522373</td>\n",
       "      <td>0.575346</td>\n",
       "      <td>0.578125</td>\n",
       "      <td>0.467484</td>\n",
       "      <td>0.590910</td>\n",
       "      <td>0.552141</td>\n",
       "      <td>0.607856</td>\n",
       "      <td>0.601968</td>\n",
       "      <td>0.535657</td>\n",
       "      <td>0.457637</td>\n",
       "      <td>0.551117</td>\n",
       "      <td>0.610363</td>\n",
       "      <td>0.480101</td>\n",
       "      <td>0.573761</td>\n",
       "      <td>0.518896</td>\n",
       "      <td>...</td>\n",
       "      <td>0.589080</td>\n",
       "      <td>0.545485</td>\n",
       "      <td>0.571707</td>\n",
       "      <td>0.498981</td>\n",
       "      <td>0.563343</td>\n",
       "      <td>0.513630</td>\n",
       "      <td>0.558023</td>\n",
       "      <td>0.500063</td>\n",
       "      <td>0.538100</td>\n",
       "      <td>0.556101</td>\n",
       "      <td>0.524660</td>\n",
       "      <td>0.457818</td>\n",
       "      <td>0.482889</td>\n",
       "      <td>0.548536</td>\n",
       "      <td>0.559314</td>\n",
       "      <td>0.510231</td>\n",
       "      <td>0.487639</td>\n",
       "      <td>0.556048</td>\n",
       "      <td>0.553153</td>\n",
       "      <td>0.548332</td>\n",
       "      <td>0.604891</td>\n",
       "      <td>0.540810</td>\n",
       "      <td>0.480729</td>\n",
       "      <td>0.537616</td>\n",
       "      <td>0.521999</td>\n",
       "      <td>0.529900</td>\n",
       "      <td>0.521071</td>\n",
       "      <td>0.445925</td>\n",
       "      <td>0.528786</td>\n",
       "      <td>0.545271</td>\n",
       "      <td>0.553623</td>\n",
       "      <td>0.460783</td>\n",
       "      <td>0.614081</td>\n",
       "      <td>0.525804</td>\n",
       "      <td>0.540561</td>\n",
       "      <td>0.490932</td>\n",
       "      <td>0.467734</td>\n",
       "      <td>0.626549</td>\n",
       "      <td>0.557838</td>\n",
       "      <td>0.524413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.585465</td>\n",
       "      <td>0.610740</td>\n",
       "      <td>0.517781</td>\n",
       "      <td>0.556169</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500372</td>\n",
       "      <td>0.570013</td>\n",
       "      <td>0.623576</td>\n",
       "      <td>0.544509</td>\n",
       "      <td>0.566309</td>\n",
       "      <td>0.591789</td>\n",
       "      <td>0.537607</td>\n",
       "      <td>0.546310</td>\n",
       "      <td>0.575351</td>\n",
       "      <td>0.569946</td>\n",
       "      <td>0.544484</td>\n",
       "      <td>0.631793</td>\n",
       "      <td>0.606118</td>\n",
       "      <td>0.602823</td>\n",
       "      <td>0.558317</td>\n",
       "      <td>0.557440</td>\n",
       "      <td>0.505204</td>\n",
       "      <td>0.513340</td>\n",
       "      <td>0.498325</td>\n",
       "      <td>0.584458</td>\n",
       "      <td>0.552691</td>\n",
       "      <td>0.662019</td>\n",
       "      <td>0.660340</td>\n",
       "      <td>0.525247</td>\n",
       "      <td>0.580918</td>\n",
       "      <td>0.511814</td>\n",
       "      <td>0.555580</td>\n",
       "      <td>0.562019</td>\n",
       "      <td>0.584817</td>\n",
       "      <td>0.495729</td>\n",
       "      <td>0.538533</td>\n",
       "      <td>0.617747</td>\n",
       "      <td>0.431302</td>\n",
       "      <td>0.514509</td>\n",
       "      <td>0.549256</td>\n",
       "      <td>...</td>\n",
       "      <td>0.605153</td>\n",
       "      <td>0.524197</td>\n",
       "      <td>0.535379</td>\n",
       "      <td>0.493007</td>\n",
       "      <td>0.545192</td>\n",
       "      <td>0.462239</td>\n",
       "      <td>0.493110</td>\n",
       "      <td>0.491888</td>\n",
       "      <td>0.536544</td>\n",
       "      <td>0.567300</td>\n",
       "      <td>0.501358</td>\n",
       "      <td>0.460066</td>\n",
       "      <td>0.536477</td>\n",
       "      <td>0.525778</td>\n",
       "      <td>0.593337</td>\n",
       "      <td>0.493285</td>\n",
       "      <td>0.502796</td>\n",
       "      <td>0.532923</td>\n",
       "      <td>0.510724</td>\n",
       "      <td>0.544733</td>\n",
       "      <td>0.595950</td>\n",
       "      <td>0.536642</td>\n",
       "      <td>0.502615</td>\n",
       "      <td>0.552876</td>\n",
       "      <td>0.553793</td>\n",
       "      <td>0.498339</td>\n",
       "      <td>0.484628</td>\n",
       "      <td>0.502945</td>\n",
       "      <td>0.519216</td>\n",
       "      <td>0.527451</td>\n",
       "      <td>0.542307</td>\n",
       "      <td>0.485210</td>\n",
       "      <td>0.559869</td>\n",
       "      <td>0.574549</td>\n",
       "      <td>0.538851</td>\n",
       "      <td>0.492888</td>\n",
       "      <td>0.451816</td>\n",
       "      <td>0.600651</td>\n",
       "      <td>0.521886</td>\n",
       "      <td>0.528850</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 4800 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0         1         2     ...      4797      4798      4799\n",
       "0  1.000000  0.543656  0.571502  ...  0.536898  0.491150  0.506592\n",
       "1  0.543656  1.000000  0.531973  ...  0.598936  0.556741  0.554506\n",
       "2  0.571502  0.531973  1.000000  ...  0.535344  0.540606  0.519636\n",
       "3  0.576771  0.526304  0.580201  ...  0.626549  0.557838  0.524413\n",
       "4  0.585465  0.610740  0.517781  ...  0.600651  0.521886  0.528850\n",
       "\n",
       "[5 rows x 4800 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_sim = cosine_similarity(doc_vecs_ft)\n",
    "doc_sim_df = pd.DataFrame(doc_sim)\n",
    "doc_sim_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MpVoDJNmOPBD"
   },
   "source": [
    "## Step by Step Methodology for Recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TGGJ_gJFuZ-o"
   },
   "source": [
    "### **Question 7**: Get a list of Movie titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QAMyZTC9ODZU",
    "outputId": "6b12a6b2-5274-4ee6-de1e-412b1a8576c8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Avatar', \"Pirates of the Caribbean: At World's End\", 'Spectre',\n",
       "       ..., 'Signed, Sealed, Delivered', 'Shanghai Calling',\n",
       "       'My Date with Drew'], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# movie titles\n",
    "movies_list = df['title'].values\n",
    "movies_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TmMMPq3-ukJV"
   },
   "source": [
    "### **Question 8**: Given a movie title, get its index value \n",
    "\n",
    "Here let's get the ID for the movie __Minions__\n",
    "\n",
    "__Hint:__ Numpy has dedicated functions to find the index from a numpy array or you can use list indexing functions also. The output should be a number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ze84U5EVOUhW",
    "outputId": "e36c4b14-0c44-4914-8952-1907409bafb4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "546"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## movie ID\n",
    "movie_idx = np.where(movies_list == 'Minions')[0][0]\n",
    "movie_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MoCHlZl9OYSk"
   },
   "source": [
    "## Get Similar Movies\n",
    "\n",
    "We already calculated pairwise similarity between all movies in our dataset. Next step is to extract moview similar to a given movie.\n",
    "\n",
    "Let us use the movie _Minions_ at index _546_ to find some similar movies using ``doc_sim_df`` dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "egLaZYx9vGP0"
   },
   "source": [
    "### **Question 9**: Extract row of dataframe given an index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UmSNFxLxOUYA",
    "outputId": "61829caa-0281-4e7a-f2f3-637c9b18e27a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.4838717 , 0.54614931, 0.54717532, ..., 0.5131163 , 0.50184772,\n",
       "       0.55177593])"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_similarities = doc_sim_df.iloc[movie_idx].values\n",
    "movie_similarities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HLgaeRlcOeMv"
   },
   "source": [
    "### Top Similar Movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q-Oa0wvlvVVb"
   },
   "source": [
    "### **Question 10**: Get top 5 most similar movies in descending order of similarity\n",
    "\n",
    "_hint: In descending order the index 0 represents the movie itself (as a movie description is 100% similar to itself, so it is safe to skip index 0_\n",
    "\n",
    "#### Get top 5 movie IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7MipUk82OjRh",
    "outputId": "80215c30-4677-43fc-b339-99eb39c44fc8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 614, 2825, 4568, 1358,  506])"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar_movie_idxs = np.argsort(-movie_similarities)[1:6]\n",
    "similar_movie_idxs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YvCvqUS1_I5n"
   },
   "source": [
    "#### Get top 5 movie names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kRofKIaaOlc1",
    "outputId": "f2766f25-2023-4de8-85fd-8960b8f16fb8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Despicable Me', 'Time Bandits',\n",
       "       'Rise of the Entrepreneur: The Search for a Better Way',\n",
       "       'Austin Powers: The Spy Who Shagged Me', 'Despicable Me 2'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar_movies = movies_list[similar_movie_idxs]\n",
    "similar_movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E3GRzdwOxVXa"
   },
   "source": [
    "## Movie Recommender\n",
    "\n",
    "Time to make use of all the smaller steps we have gone through so far to prepare a recommendation utility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lpB52SSIxbkk"
   },
   "source": [
    "### **Question 11**: Complete the utility function for getting movie recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "dL9JZc_Tw96e"
   },
   "outputs": [],
   "source": [
    "def movie_recommender(movie_title, movies=movies_list, doc_sims=None):\n",
    "    # find movie id\n",
    "    movie_idx = np.where(movies == movie_title)[0][0]\n",
    "\n",
    "    # get movie similarities. \n",
    "    #Hint: movie index helps find the exact row\n",
    "    movie_similarities = doc_sims.iloc[movie_idx].values\n",
    "    \n",
    "    # get top 5 similar movie IDs\n",
    "    # Hint: use numpy utility to do a sort\n",
    "    similar_movie_idxs = np.argsort(-movie_similarities)[1:6]\n",
    "    \n",
    "    # get top 5 movies\n",
    "    similar_movies = movies[similar_movie_idxs]\n",
    "    \n",
    "    # return the top 5 movies\n",
    "    return similar_movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vkH9veWqyljn"
   },
   "source": [
    "### Find Similar Movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "0b2mQR5yyxxY"
   },
   "outputs": [],
   "source": [
    "popular_movies = ['Minions', 'Interstellar', 'Deadpool', 'Jurassic World', 'Pirates of the Caribbean: The Curse of the Black Pearl',\n",
    "              'Dawn of the Planet of the Apes', 'The Hunger Games: Mockingjay - Part 1', 'Terminator Genisys', \n",
    "              'Captain America: Civil War', 'The Dark Knight', 'The Martian', 'Batman v Superman: Dawn of Justice', \n",
    "              'Pulp Fiction', 'The Godfather', 'The Shawshank Redemption', 'The Lord of the Rings: The Fellowship of the Ring',  \n",
    "              'Harry Potter and the Chamber of Secrets', 'Star Wars', 'The Hobbit: The Battle of the Five Armies',\n",
    "              'Iron Man']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xLtf6tM3ymN7",
    "outputId": "0e3ff13a-d0ff-4a22-e591-0f148bc7b61e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie: Minions\n",
      "Top 5 recommended Movies: ['Despicable Me' 'Time Bandits'\n",
      " 'Rise of the Entrepreneur: The Search for a Better Way'\n",
      " 'Austin Powers: The Spy Who Shagged Me' 'Despicable Me 2']\n",
      "\n",
      "Movie: Interstellar\n",
      "Top 5 recommended Movies: ['Prometheus' 'Gattaca' 'Starship Troopers'\n",
      " 'Sea Rex 3D: Journey to a Prehistoric World' 'Space Cowboys']\n",
      "\n",
      "Movie: Deadpool\n",
      "Top 5 recommended Movies: ['Banshee Chapter' 'Fantastic Four' 'Enough' 'The Hunted' 'Spider-Man 3']\n",
      "\n",
      "Movie: Jurassic World\n",
      "Top 5 recommended Movies: ['Jurassic Park' 'The Lost World: Jurassic Park' 'Jurassic Park III'\n",
      " \"National Lampoon's Vacation\" 'Walking With Dinosaurs']\n",
      "\n",
      "Movie: Pirates of the Caribbean: The Curse of the Black Pearl\n",
      "Top 5 recommended Movies: ['Pirates of the Caribbean: On Stranger Tides'\n",
      " 'The Pirates! In an Adventure with Scientists!'\n",
      " \"Pirates of the Caribbean: Dead Man's Chest\"\n",
      " 'In the Name of the King III' 'American Ninja 2: The Confrontation']\n",
      "\n",
      "Movie: Dawn of the Planet of the Apes\n",
      "Top 5 recommended Movies: ['Battle for the Planet of the Apes' 'Conquest of the Planet of the Apes'\n",
      " 'Beneath the Planet of the Apes' 'Rise of the Planet of the Apes'\n",
      " 'Hard to Be a God']\n",
      "\n",
      "Movie: The Hunger Games: Mockingjay - Part 1\n",
      "Top 5 recommended Movies: ['The Hunger Games: Catching Fire' 'The Hunger Games: Mockingjay - Part 2'\n",
      " 'The Hunger Games' 'Bran Nue Dae' 'Rust']\n",
      "\n",
      "Movie: Terminator Genisys\n",
      "Top 5 recommended Movies: ['Terminator 2: Judgment Day' 'Terminator Salvation'\n",
      " 'X-Men: Days of Future Past' 'Terminator 3: Rise of the Machines'\n",
      " 'The Terminator']\n",
      "\n",
      "Movie: Captain America: Civil War\n",
      "Top 5 recommended Movies: ['Captain America: The Winter Soldier' 'Avengers: Age of Ultron'\n",
      " 'Star Trek Into Darkness' 'Iron Man 2' 'Divergent']\n",
      "\n",
      "Movie: The Dark Knight\n",
      "Top 5 recommended Movies: ['The Dark Knight Rises' 'Batman: The Dark Knight Returns, Part 2'\n",
      " 'Batman Returns' 'Batman Forever' 'Batman']\n",
      "\n",
      "Movie: The Martian\n",
      "Top 5 recommended Movies: ['Battleship' 'Alien' 'Red Planet' 'Sanctum'\n",
      " 'Star Trek IV: The Voyage Home']\n",
      "\n",
      "Movie: Batman v Superman: Dawn of Justice\n",
      "Top 5 recommended Movies: ['Batman: The Dark Knight Returns, Part 2' 'Defendor' 'The Dark Knight'\n",
      " 'Batman Begins' 'Batman Returns']\n",
      "\n",
      "Movie: Pulp Fiction\n",
      "Top 5 recommended Movies: ['Locker 13' 'Sliding Doors' '11:14' 'The Sting' 'Crying with Laughter']\n",
      "\n",
      "Movie: The Godfather\n",
      "Top 5 recommended Movies: ['The Godfather: Part II' 'The Godfather: Part III' 'Loose Cannons'\n",
      " 'Machete' 'The Color Purple']\n",
      "\n",
      "Movie: The Shawshank Redemption\n",
      "Top 5 recommended Movies: ['Civil Brand' 'Prison' 'Escape Plan' 'Get Hard' 'Bridge of Spies']\n",
      "\n",
      "Movie: The Lord of the Rings: The Fellowship of the Ring\n",
      "Top 5 recommended Movies: ['The Lord of the Rings: The Two Towers'\n",
      " 'The Hobbit: An Unexpected Journey'\n",
      " 'The Lord of the Rings: The Return of the King'\n",
      " 'The Hobbit: The Desolation of Smaug'\n",
      " 'The Hobbit: The Battle of the Five Armies']\n",
      "\n",
      "Movie: Harry Potter and the Chamber of Secrets\n",
      "Top 5 recommended Movies: ['Harry Potter and the Goblet of Fire'\n",
      " 'Harry Potter and the Prisoner of Azkaban'\n",
      " 'Harry Potter and the Order of the Phoenix'\n",
      " \"Harry Potter and the Philosopher's Stone\"\n",
      " 'Harry Potter and the Half-Blood Prince']\n",
      "\n",
      "Movie: Star Wars\n",
      "Top 5 recommended Movies: ['The Empire Strikes Back' 'Return of the Jedi'\n",
      " 'Star Wars: Episode III - Revenge of the Sith'\n",
      " 'Star Wars: Episode II - Attack of the Clones' 'The Ice Pirates']\n",
      "\n",
      "Movie: The Hobbit: The Battle of the Five Armies\n",
      "Top 5 recommended Movies: ['The Hobbit: The Desolation of Smaug' 'The Hobbit: An Unexpected Journey'\n",
      " \"Dragon Nest: Warriors' Dawn\"\n",
      " 'Star Wars: Episode III - Revenge of the Sith' '300: Rise of an Empire']\n",
      "\n",
      "Movie: Iron Man\n",
      "Top 5 recommended Movies: ['Iron Man 2' 'Avengers: Age of Ultron' 'Mystery Men' 'Batman Begins'\n",
      " 'Iron Man 3']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for movie in popular_movies:\n",
    "    print('Movie:', movie)\n",
    "    print('Top 5 recommended Movies:', movie_recommender(movie_title=movie, movies=movies_list, doc_sims=doc_sim_df))\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Exercise 1 - Movie Recommender System with FastText Solutions.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
